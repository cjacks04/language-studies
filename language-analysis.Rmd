---
title: "Language Socialization"
author: "Corey Jackson"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}

# add libraries
library(reshape2)
library(hrbrthemes)
library(scales)
library(ggsci)
library(data.table)
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(lubridate)
library(lme4)
# import science
cos_science <- read_csv("/Volumes/cbjackson2/language models/outputs/astronomy/Agg_Weekly_cos_result_Astro.csv") 
science_theil <- read_csv("/Volumes/cbjackson2/language models/outputs/astronomy/3M_Agg_Theil_result_Astro.csv") 
science_cpd <- read_csv("/Volumes/cbjackson2/language models/outputs/astronomy/3M_Agg_CPD_result_Astro.csv") 

names(science_theil)[1] <- "user_id"
science_theil$first_comment <- mdy_hm (science_theil$first_comment)
science_theil$last_comment <- mdy_hm(science_theil$last_comment)
science_theil$comment_tenure <- difftime(science_theil$last_comment,science_theil$first_comment, units = "days")
science_theil$user_id <- as.factor(science_theil$user_id)

names(science_cpd) <- c("user_id","sci_change_points")
science_cpd$sci_changes <- str_count(science_cpd$sci_change_points, ',')

# import domain 
cos_domain <- read_csv("/Volumes/cbjackson2/language models/outputs/domain/Agg_Weekly_cos_result.csv") 
domain_theil <- read_csv("/Volumes/cbjackson2/language models/outputs/domain/3M_Agg_Theil_result.csv") 
domain_cpd <- read_csv("/Volumes/cbjackson2/language models/outputs/domain/3M_Agg_CPD_result.csv") 

names(domain_theil)[1] <- "user_id"
names(domain_cpd) <- c("user_id","domain_change_points")
domain_cpd$domain_changes <- str_count(domain_cpd$domain_change_points, ',')
domain_theil$user_id <- as.factor(domain_theil$user_id)

user_lan <- merge(domain_cpd,domain_theil, by = "user_id")
user_lan <- merge(user_lan,science_cpd, by = "user_id")
user_lan <- merge(user_lan,science_theil, by = "user_id")
user_lan <- user_lan[,c(1:7,11:20)]

names(user_lan)[c(4:7,10:16)] <- c("dslope","dintercept","dlowslope","dhighslope","sslope","sintercept","slowslope","shighslope","first_comment","last_comment","comment_number")

remove(domain_cpd,domain_theil,science_cpd,science_theil)
classifications <- read_csv("/Volumes/cbjackson2/Zooniverse Datasets/gravityspy/classifications_reduced031422.csv") # move to Zoonvierse Datasets folder
classifications$created_at2 <- as.POSIXct(classifications$created_at , format="%Y-%m-%d %H:%M:%S") # The time the classification is recorded in the Zooniverse database see: https://github.com/zooniverse/Data-digging/blob/master/docs/classification_export_field_descriptors.txt

comments <- read_csv("/Volumes/cbjackson2/Zooniverse Datasets/gravityspy/gravity-spy-comments_2022-07-15.csv") # move to Zoonvierse Datasets folder

comments$created_at <- as.POSIXct(comments$comment_created_at , format="%Y-%m-%d %H:%M:%S")
comments <- comments[which(comments$created_at <= "2022-03-14 15:39:44"),]

#earliest overlapping record is "2022-03-14 15:39:44 UTC"
```

```{r setup-classifications, include=FALSE, warning=FALSE}
session_builder1 <- data.frame(classifications$classification_id,classifications$user_id,as.character(classifications$created_at2),"classification")
names(session_builder1)[c(1:4)] <- c("id","user_id","created_at","type")

session_builder2 <- data.frame(comments$comment_id,comments$comment_user_id,as.character(comments$created_at),"comment")
names(session_builder2)[c(1:4)] <- c("id","user_id","created_at","type")

session_builder <- rbind(session_builder1,session_builder2)
remove(session_builder1,session_builder2)
session_builder$user_id <- as.factor(session_builder$user_id)
session_builder$created_at <- as.POSIXct(session_builder$created_at , format="%Y-%m-%d %H:%M:%S")

# Add session information for classifications 
session_builder <- session_builder[order(session_builder$user_id,session_builder$created_at),]
session_builder <- data.table(session_builder)

session_builder <- session_builder[,session:=paste(cumsum(c(1,diff(created_at) > 1800)),sep="."),by=user_id]
session_builder <- session_builder[,act_seq := sequence(.N), by = c("user_id")] # order of events

if(any(grepl("package:plyr", search()))) detach("package:plyr") else message("plyr not loaded")
library(dplyr)

user_session <- session_builder %>% 
   group_by(user_id = as.factor(user_id),session) %>%  
   summarise(
   class = length(which(type=="classification")),
   comment = length(which(type=="comment")),
   start = min(created_at),
   end = max(created_at)
   )

user_week <- session_builder %>% 
   group_by(user_id = as.factor(user_id),week=floor_date(created_at, "week")) %>%  
   summarise(
   class = length(which(type=="classification")),
   comment = length(which(type=="comment")),
   sessions = length(unique(session)),
   start = min(created_at),
   end = max(created_at)
   )

user_info <- session_builder %>% 
   group_by(user_id = as.factor(user_id)) %>%  
   summarise(
   class = length(which(type=="classification")),
   comment = length(which(type=="comment")),
   join_date = min(created_at),
   recent_date = max(created_at),
   sessions = length(unique(session)),
   first_comment_seq = min(act_seq[which(type=="comment")]),
   first_comment_ses = min(session[which(type=="comment")]),
   newcomer_end = as.POSIXct(join_date + lubridate::days(30), format="%Y-%m-%d %H:%M:%S"),
   retained=ifelse(recent_date>newcomer_end,1,0))

```

```{r setup-domain, include=FALSE}
# ANALYSIS OF science LANGUAGE
wc_s <- data.frame(t(cos_science)) # transpose
wc_s <- cbind(rownames(wc_s),wc_s); colnames(wc_s) <- wc_s[1,]; names(wc_s)[1] <- "user_id"; wc_s <- wc_s[-c(1),]; rownames(wc_s) <- 1:dim(wc_s)[1] # Fix dataframe row/columns

wc_s.m <- melt(wc_s, id=c("user_id")) #convert dataframe from wide to long
wc_s.m <- as.data.table(wc_s.m)[, realweek := 1:.N,, by = list(user_id)] # add counter for user for each week 
wc_s.m <- wc_s.m[which(!is.na(wc_s.m$value)),] # remove NA values
wc_s.m <- as.data.table(wc_s.m)[, commentweek := 1:.N,, by = list(user_id)]  # add counter for user for each week user commented
wc_s.m <- data.frame(wc_s.m)
wc_s.m$value <- as.numeric(wc_s.m$value)

wc_s.m <- wc_s.m %>%
    group_by(user_id) %>%
    mutate(last_session = realweek - lag(realweek, default = first(realweek), order_by = commentweek),
           cos_diff = value - lag(value, default = first(value), order_by = commentweek))

wc_s.m.real <- ggplot(wc_s.m, aes(x = realweek, y = value)) +  # plot cosine for each week (remove NAs)
      stat_summary(fun = "mean",geom = "point") + 
      geom_smooth() +
      labs(x = "Actual week", y  = "Cosine similarity") + 
      #xlim(1,12) +
      theme_ipsum() +
      theme(plot.margin = unit(c(.1,.1,.1,.1), "cm"))

wc_s.m.comment <- ggplot(wc_s.m, aes(x = commentweek, y = value)) + # plot cosine for each week user commented (remove NAs)
      stat_summary(fun = "mean",geom = "point") + 
      geom_smooth() +
      xlim(1,100) +
      labs(x = "Comment week", y  = "Cosine similarity") + 
      theme_ipsum() +
      theme(plot.margin = unit(c(.1,.1,.1,.1), "cm"))

# ANALYSIS OF science LANGUAGE
wc_d <- data.frame(t(cos_domain)) # transpose
wc_d <- cbind(rownames(wc_d),wc_d); colnames(wc_d) <- wc_d[1,]; names(wc_d)[1] <- "user_id"; wc_d <- wc_d[-c(1),]; rownames(wc_d) <- 1:dim(wc_d)[1] # Fix dataframe row/columns

wc_d.m <- melt(wc_d, id=c("user_id")) #convert dataframe from wide to long
wc_d.m <- as.data.table(wc_d.m)[, realweek := 1:.N,, by = list(user_id)] # add counter for user for each week 
wc_d.m <- wc_d.m[which(!is.na(wc_d.m$value)),] # remove NA values
wc_d.m <- as.data.table(wc_d.m)[, commentweek := 1:.N,, by = list(user_id)]  # add counter for user for each week user commented

wc_d.m <- data.frame(wc_d.m)
wc_d.m$value <- as.numeric(wc_d.m$value)

wc_d.m <- wc_d.m %>%
    group_by(user_id) %>%
    mutate(last_session = realweek - lag(realweek, default = first(realweek), order_by = commentweek),
           cos_diff = value - lag(value, default = first(value), order_by = commentweek))

wc_d.m.real <- ggplot(wc_d.m, aes(x = realweek, y = value)) +  # plot cosine for each week (remove NAs)
      stat_summary(fun = "mean",geom = "point") + 
      geom_smooth() +
      labs(x = "Actual week", y  = "Cosine similarity") + 
      #xlim(1,12) +
      theme_ipsum() +
      theme(plot.margin = unit(c(.1,.1,.1,.1), "cm"))

wc_d.m.comment <- ggplot(wc_d.m, aes(x = commentweek, y = value)) + # plot cosine for each week user commented (remove NAs)
      stat_summary(fun = "mean",geom = "point") + 
      geom_smooth() +
      xlim(1,100) +
      labs(x = "Comment week", y  = "Cosine similarity") + 
      theme_ipsum() +
      theme(plot.margin = unit(c(.1,.1,.1,.1), "cm"))
```

```{r models, warning=FALSE,error=FALSE}
# Create dataset for modeling. 
# Retention =

#NEED: lang.sim + change.pt + slope  (during newcomer period first four weeks)
#DONE: lurking period + number of tasks + number of comments + sessions

session_builder_newcomer <- merge(session_builder,
                                  user_info[,c("user_id","newcomer_end","retained")], by="user_id")

session_builder_newcomer$n_period <- ifelse(session_builder_newcomer$created_at<=session_builder_newcomer$newcomer_end,1,0)


session_builder_newcomer <- session_builder_newcomer[which(session_builder_newcomer$n_period==1),]
session_builder_newcomer <- data.frame(session_builder_newcomer)

session_builder_newcomer$act_seq <- as.character(session_builder_newcomer$act_seq)

newcomer_info <- session_builder_newcomer %>% 
   group_by(user_id = as.factor(user_id)) %>%  
   summarise(
   newcomer_class = length(which(type=="classification")),
   newcomer_comment = length(which(type=="comment")),
   join_date = min(created_at),
   newcomer_recent_date = max(created_at),
   newcomer_sessions = length(unique(session)),
   newcomer_first_comment_seq = min(act_seq[which(type=="comment")]),
   newcomer_first_comment_ses = min(session[which(type=="comment")]))

# merge user_info and newcomer_info
newcomer_info <- data.frame(newcomer_info)
user_info <- data.frame(user_info)

newcomer_info <- merge(newcomer_info,user_info[,c("user_id","class","comment","recent_date","sessions","first_comment_seq","first_comment_ses")], by="user_id")

# Newcomer period for all users
newcomer_info <- merge(newcomer_info,user_lan[,c(1:13)],by="user_id",all.x=TRUE )


#retention.glm <- glm(retained ~ IVs, data = )

#NEED: lang.sim + change.pt + slope  (during newcomer period first four weeks)
#DONE: lurking period + number of tasks + number of comments + sessions

### SIMILARITY MODELS

#Similarity = number of session + days since start  + classifications + comments + gap( difference between current and previous week + (1|user_id)

#similarity.mef <- nlme(similarity ~ IVs, data = )
```



## Science cosine language
```{r, echo=FALSE}

```

```{r}
wc_s.m.real
wc_s.m.comment
```



## Domain cosine language
```{r}
wc_d.m.real
wc_d.m.comment
```

#https://m-clark.github.io/mixed-models-with-R/introduction.html

