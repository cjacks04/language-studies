---
title: "Linguistic Similarity Gravity Spy and Snapshot"
author: "Corey Jackson"
date: "`r Sys.time()`"
output:
  html_document:
    fig_caption: yes
    highlight: pygments
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 3
    toc_float:
      smooth_scroll: no
  pdf_document:
    toc: yes
    toc_depth: '2'
#bibliography: skills.bib
always_allow_html: yes
---


```{r environment, echo=FALSE,message=FALSE,warning=FALSE}

library(lubridate)
library(readr)
library(data.table)
library(tidytext)
library(entropy)
library(reshape2)
library(ggplot2)
library(scales)
library(dplyr)
library(tm)
library(rapport)
library(knitr)
library(kableExtra)
library(corpus)
library(cowplot)
library(gridExtra)
library(caret)
library(rcompanion)
library(pROC)
library(AER)
library(plm)
library(lme4)
library(stargazer)

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          median = median   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

# A function for calculating entropy. Takes only rows as values
entfun <- function(x)
{
 	entropy(x, method = "ML")
}

if(any(grepl("package:plyr", search()))) detach("package:plyr") else message("plyr not loaded")
library(dplyr)

### Project Organizers

#### Gravity Spy
gsorganizers_name <- c("uber_pye","areeda","mzevin1","RF45","jrsmith02","sbc538","adamamiller","olipatane","smarttiz","jafeldt","mcoughlin","citizenscientist1994","cjackso3","camallen","lmp579","sciencejedi","crowston","Carsten","jessiemcd","ejm553","srallen","costerlu@syr.edu","lcalian","joeykey","matsoulina","trouille","zooniverse","achilles308","futurewaves","wavewavewave","EcceruElme")

gsproject_org <- c("uber_pye","areeda","mzevin1","RF45","jrsmith02","sbc538","adamamiller","olipatane","smarttiz","jafeldt","mcoughlin","citizenscientist1994","cjackso3","camallen","lmp579","sciencejedi","crowston","Carsten","jessiemcd","ejm553","srallen","costerlu@syr.edu","lcalian","joeykey","matsoulina","trouille","zooniverse") #exculdes moderators

# Gravity Spy roles
gsexperts <- c("uber_pye","areeda","mzevin1","RF45","jrsmith02","sbc538")
gscollaborators <- c("adamamiller","olipatane","smarttiz","jafeldt","mcoughlin","citizenscientist1994","cjackso3", "camallen","lmp579","sciencejedi","crowston","Carsten","jessiemcd","ejm553","srallen","costerlu@syr.edu","lcalian","joeykey","matsoulina","trouille","zooniverse")
gsmoderators <- c("achilles308","futurewaves","wavewavewave","EcceruElme")

#### Snapshot Serengheti
ssorganizers_name <- c("kosmala")

ssproject_org <- c() #exculdes moderators

# Gravity Spy roles
ssexperts <- c()
sscollaborators <- c()
ssmoderators <- c()

```

```{r import, echo=FALSE,message=FALSE,warning=FALSE,cache=TRUE}

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Dataset") # set RD

zoonivere_join_date <- read_csv("~/Dropbox/INSPIRE/Data/Zooniverse Projects + Users/joindatequery-5-24-19.csv") # ON RD

# gravity spy users
gs_join <- zoonivere_join_date[which(zoonivere_join_date$project_id==1104),]
# snapshot users
ss_join <-zoonivere_join_date[which(zoonivere_join_date$project_id== 40),]

remove(zoonivere_join_date)

###################### Gravity Spy Geordi data 
geordi <- read_csv("geordi-cleaned.csv", 
     col_types = cols(X1 = col_skip(), userID = col_character()))

gscomments <- read_csv("Comment Data/gravity-spy-comments_2019-07-26.csv", 
     col_types = cols(X1 = col_skip(), userID = col_character()))

gsmonth_cosine <- read_csv("Cosine Similarity/gravityspy/GravitySpy_user_in_month.csv") #ON RD
gsmonth_cosine2 <- gsmonth_cosine
###################### Snapshot Serengeti data 

sscomments <- read_csv("Comment Data/snapshot_prep2.csv") #on RD
ssmonth_cosine <- read_csv("Cosine Similarity/snapshot/Snapshot_user_in_month.csv") #on RD
```

```{r munging, echo=FALSE,message=FALSE,warning=FALSE,cache=TRUE}
## get only view data from geordi
view_events <- c("class-talk", "notes-view","help-view", "talk-view","chat-view","view-discussion","boardNew Glitch Classes-view-discussion", "boardChat-view-discussion", "boardBug reports-view-discussion", "boardScience-view-discussion","boardHelp-view-discussion","bugs-view", "boardNotes-view-discussion","boardCollections-view-discussion","collections-view", "glitches-view","science-view","open-field-guide","mini-course","tutorial-completion")

# Get view data by month and board name
geordi_views <- geordi[which(geordi$new.category  %in% view_events),]

## geordi data stops before comment data so need to match these two datasets
geordi_end <- max(geordi_views$time)
geordi_start <- min(geordi_views$time)
remove(geordi)

# remove all data from comments, geordi, and cosine prior to  2017-11-01 (not inclusive) or month 20 (not inclusive) because of discrepancy in when data were collected
gscomments <- gscomments[which(gscomments$comment_created_at < as.Date("2017-11-01")),] 
gsmonth_cosine <- gsmonth_cosine[which(gsmonth_cosine$month < 21),]

gs_join <- gs_join[which(gs_join$project_first_interact <  as.Date("2017-12-01")),]

# Some users don't have names in the joindate file because they never classified, only posted or interacted.
geordi_views <- merge(geordi_views,gs_join, by.x="userID",by.y = "user_id", all.x = TRUE)
geordi_views <- geordi_views[which(!is.na(geordi_views$user_created_at) & geordi_views$userID %in% gsmonth_cosine$comment_user_id),]

# Level Snapshot comments to match same length as Gravity Spy
sscomments <- sscomments[which(sscomments$created_at <= "2014-07-30"),] 
ssmonth_cosine <- ssmonth_cosine[which(ssmonth_cosine$month < 21),]
```

```{r commentsummary, echo=FALSE,message=FALSE,warning=FALSE,cache=TRUE}

# Gravity Spy comment summaries
gsuser_summary <- gscomments %>% 
  group_by(comment_user_login) %>% 
  summarize(
    total_comments=length(comment_user_login),                                            
    first_post = min(floor_date(comment_created_at, "month")),
    months_posting = length(unique(floor_date(comment_created_at, "month")))
           )
gsmonths <- as.data.frame(unique(floor_date(gscomments$comment_created_at, "month")))
names(gsmonths)[1] <- "month"
gsmonths <- gsmonths[order(gsmonths$month),]
gsmonths <- as.data.frame(gsmonths)
gsmonths$num <-  1:nrow(gsmonths)
names(gsmonths)[1] <- "month"

# Gravity Spy view summaries
gsuser_Vsummary <- geordi_views %>% 
  group_by(userID) %>% 
  summarize(total_views=length(userID),                                                     first_view = min(floor_date(time, "month")),
            months_viewing = length(unique(floor_date(time, "month")))
           )

# Gravity Spy comment summaries
ssuser_summary <- sscomments %>% 
  group_by(user_name) %>% 
  summarize(total_comments=length(user_name),                                                  first_post = min(floor_date(created_at, "month")),
            months_posting = length(unique(floor_date(created_at, "month")))
           )

ssmonths <- as.data.frame(unique(floor_date(sscomments$created_at, "month")))
names(ssmonths)[1] <- "month"
ssmonths <- ssmonths[order(ssmonths$month),]
ssmonths <- as.data.frame(ssmonths)
ssmonths$num <-  1:nrow(ssmonths)
names(ssmonths)[1] <- "month"
```


# Method



The records are views of `r length(view_events)` discussion threads and other project resources listed here:

__`r view_events`__

## Cosine similarity
In the equation, the documents A and B are described by vectors including the term frequency of n terms where A is the volunteers’s terms and B is the terms of the community, n is the total number of individual terms in the corpus. Cosine values range between -1 and 1, where a score of 1 is perfectly similar to the community’s language and a score of -1 is perfectly dissimilar. Thus, a volunteer having a cosine similarity score of 1 repeated the same words as the community with the same frequency observed in the community vector. For each month, we computed the cosine similarity for each volunteer with the community vector. For each volunteer, we created vectorized unigrams for each month and aggregated contributions from previous months. To avoid penalizing linguistic innovations we removed unigrams that volunteers introduced, but were not adopted by other volunteers in the community.

\[ similarity(A,B) = \frac{A \cdot B}{\parallel A\parallel x \parallel B\parallel} =  \frac{\displaystyle\sum_{i=1}^{n} \quad {A_{i} \: x \: B_{i}}} {\sqrt{\displaystyle\sum_{i=1}^{n} A_i^2} \quad x \quad \sqrt{\displaystyle\sum_{i=1}^{n} B_i^2}} \]

# Results
## Community Linguistic Trajectories
```{r , echo=FALSE,message=FALSE,warning=FALSE}
# Get monthly contributions counts
gs_summary <- gsmonth_cosine %>% 
  group_by(month) %>% 
  summarize(
    volunteers = length(comment_user_id),
    comments_posted = sum(n_post),
    unigrams_posted = sum(n_unigram),
    uniquevol_unigrams = sum(n_unique),
    newvol_unigrams = sum(n_newword)
            )
gs_summary$project <- "Gravity Spy"

ss_summary <- ssmonth_cosine %>% 
  group_by(month) %>% 
  summarize(
    volunteers = length(user_name),
    comments_posted = sum(n_post),
    unigrams_posted = sum(n_unigram),
    uniquevol_unigrams = sum(n_unique),
    newvol_unigrams = sum(n_newword)
            )
ss_summary$project <- "Snapshot Serengeti"
projectsummary <- rbind(ss_summary,gs_summary)
#remove(ss_summary,gs_summary)

## visualize counts
projectsummary.m <- melt(projectsummary, id = c("month","project"))
projectsummary.m$Type[projectsummary.m$variable=="volunteers"] <- "Volunteers"
projectsummary.m$Type[projectsummary.m$variable=="comments_posted"] <- "Comments"
projectsummary.m$Type[projectsummary.m$variable=="unigrams_posted"] <- "Unigrams"
projectsummary.m$Type[projectsummary.m$variable=="uniquevol_unigrams"] <- "Unique Unigram (Vol.)"
projectsummary.m$Type[projectsummary.m$variable=="newvol_unigrams"] <- "New Unigram (Vol.)"
names(projectsummary.m) <- c("Month","Project","Value","Count","Type")


projectsummary_viz <- ggplot(data=projectsummary.m, 
                        aes(x=Month, y=log(Count),group=Project, colour=Project)) +
  geom_line(aes(linetype=Project))  + 
  scale_color_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + theme_minimal() +
  facet_grid(Type~.,scales="free_y") + 
  labs(x = "Project Month",y="Count, log-scaling")+
  theme(
        axis.text.x = element_text(size=9), 
        axis.title=element_text(size=14),  
        legend.text=element_text(size=9),
        strip.text = element_text(size = 5, angle = 45),
        #strip.text.y = element_text(size = 12),
        legend.position = c(0.8, 0.05),
        legend.title = element_blank()
        )

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("projectsummary_viz.pdf",width = 7, height = 4)
projectsummary_viz
dev.off()
#remove(projectsummary.m)

#normalized month summaries GS
gsmonth_cosine <- as.data.table(gsmonth_cosine)
gsmonth_cosine[, normmonthpost := sequence(.N), by = c("comment_user_login")]
gsmonth_cosine <- as.data.frame(gsmonth_cosine)
#normalized month summaries SS
ssmonth_cosine <- as.data.table(ssmonth_cosine)
ssmonth_cosine[, normmonthpost := sequence(.N), by = c("user_name")]
ssmonth_cosine <- as.data.frame(ssmonth_cosine)

# Get normalized contributions counts. At each persons N month what they contributed
gs_normalizedsummary <- gsmonth_cosine %>% 
  group_by(normmonthpost) %>% 
  summarize(
    volunteers = length(comment_user_id),
    comments_posted = sum(n_post),
    unigrams_posted = sum(n_unigram),
    uniquevol_unigrams = sum(n_unique),
    newvol_unigrams = sum(n_newword)
            )
gs_normalizedsummary$project <- "Gravity Spy"

ss_normalizedsummary <- ssmonth_cosine %>% 
  group_by(normmonthpost) %>% 
  summarize(
    volunteers = length(user_name),
    comments_posted = sum(n_post),
    unigrams_posted = sum(n_unigram),
    uniquevol_unigrams = sum(n_unique),
    newvol_unigrams = sum(n_newword)
            )
ss_normalizedsummary$project <- "Snapshot Serengeti"

normalized_summary <- rbind(gs_normalizedsummary,ss_normalizedsummary)
#remove(ss_normalizedsummary,gs_normalizedsummary)

## visualize volunteer counts by normalized month
normalized_summary.m <- melt(normalized_summary, id = c("normmonthpost","project"))
normalized_summary.m$Type[normalized_summary.m$variable=="volunteers"] <- "Volunteers"
normalized_summary.m$Type[normalized_summary.m$variable=="comments_posted"] <- "Comments"
normalized_summary.m$Type[normalized_summary.m$variable=="unigrams_posted"] <- "Unigrams"
normalized_summary.m$Type[normalized_summary.m$variable=="uniquevol_unigrams"] <- "Unique Unigram"
normalized_summary.m$Type[normalized_summary.m$variable=="newvol_unigrams"] <- "New Unigram"
names(normalized_summary.m) <- c("Month","Project","Value","Count","Type")

projectsummarynormalized_viz <- ggplot(data=normalized_summary.m, 
                        aes(x=Month, y=log(Count),group=Project, colour=Project)) +
  geom_line(aes(linetype=Project))  + 
  scale_color_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + theme_minimal() +
  facet_grid(Type~.,scales="free_y") + 
  labs(x = "Volunteer Month",y="Count, log-scaling")+
  theme(
        axis.text.x = element_text(size=9), 
        axis.text.y = element_text(size=9), 
        legend.text=element_text(size=9),
        strip.text = element_text(size = 5, angle = 45),
        #strip.text.y = element_text(size = 12),
        legend.position = c(0.8, 0.1),
        legend.title = element_blank()
        )

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("projectsummarynormalized_viz.pdf",width = 7, height = 4)
projectsummarynormalized_viz
dev.off()

#remove(normalized_summary.m)

# Get contributions summary statistics mean...

# combined cosine data
gsmonth_cosine$project <- "Gravity Spy"
names(gsmonth_cosine)[1] <- "user_name"
gsmonth_cosine_original <-  gsmonth_cosine# one additional column in gs so can't combine with ss. Save original can remove extra column 
gsmonth_cosine <- gsmonth_cosine[,-2]
gsmonth_cosine$project <- "Gravity Spy"
ssmonth_cosine$project <- "Snapshot Serengeti"
usersummarydata <- rbind(gsmonth_cosine,ssmonth_cosine)

usersummarydata.m <- melt(usersummarydata, id = c("project","month","user_name"))
usersummarydata.m <- usersummarydata.m[which(!usersummarydata.m$variable %in% c("normmonthpost","cosine_similarity")),] # remove normmonthpost
usersummarydata.m$Type[usersummarydata.m$variable=="n_post"] <- "Comments"
usersummarydata.m$Type[usersummarydata.m$variable=="n_unigram"] <- "Unigrams"
usersummarydata.m$Type[usersummarydata.m$variable=="n_unique"] <- "Unique Unigrams"
usersummarydata.m$Type[usersummarydata.m$variable=="n_newword"] <- "New Unigrams"
names(usersummarydata.m) <- c("Project","Month","User","Value","Count","Type")

library(plyr)
tgc <- summarySE(usersummarydata.m, measurevar="Count", groupvars=c("Project","Type","Month"))

meansummary_viz <- ggplot(data=tgc, 
                        aes(x=Month, y=Count, fill=Project)) +
  geom_bar(stat = "identity",position = 'dodge')  + 
  scale_fill_manual(values=c("#56B4E9", "#009E73")) +
  theme_classic() + theme_minimal() +
  facet_grid(Type~.,scales="free_y") + 
  labs(x = "Project Month",y=expression(~(mu)~Contribution)) +
  theme(
        axis.text.x = element_text(size=9), 
        axis.text.y = element_text(size=9), 
        legend.text=element_text(size=9),
        strip.text = element_text(size = 8, angle = 45),
        #strip.text.y = element_text(size = 12),
        legend.position = c(0.85, 0.18),
        legend.title = element_blank()
        )

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("meansummary_viz.pdf",width = 7, height = 4)
meansummary_viz
dev.off()

# Get normalized contribution summary statistics At each persons N month what they contributed
usersummarydatanormalized.m <- melt(usersummarydata, id = c("project","normmonthpost","user_name"))

usersummarydatanormalized.m <- usersummarydatanormalized.m[which(!usersummarydatanormalized.m$variable %in% c("month","cosine_similarity")),] # remove normmonthpost
usersummarydatanormalized.m$Type[usersummarydatanormalized.m$variable=="n_post"] <- "Comments"
usersummarydatanormalized.m$Type[usersummarydatanormalized.m$variable=="n_unigram"] <- "Unigrams"
usersummarydatanormalized.m$Type[usersummarydatanormalized.m$variable=="n_unique"] <- "Unique Unigrams"
usersummarydatanormalized.m$Type[usersummarydatanormalized.m$variable=="n_newword"] <- "New Unigrams"
names(usersummarydatanormalized.m) <- c("Project","NormalizedMonth","User","Value","Count","Type")

tgc2 <- summarySE(usersummarydatanormalized.m, measurevar="Count", groupvars=c("Project","Type","NormalizedMonth"))

normalizedmeansummary_viz <- ggplot(data=tgc2, 
                        aes(x=NormalizedMonth, y=Count, fill=Project)) +
  geom_bar(stat = "identity",position = 'dodge')  + 
  scale_fill_manual(values=c("#56B4E9", "#009E73")) +
  theme_classic() + theme_minimal() +
  facet_grid(Type~.,scales="free_y") + 
  labs(x = "Volunteer Month",y=expression(~(mu)~Contribution)) +
  theme(
        axis.text.x = element_text(size=9), 
        axis.text.y = element_text(size=9), 
        legend.text=element_text(size=9),
        strip.text = element_text(size = 8, angle = 45),
        #strip.text.y = element_text(size = 12),
        legend.position = c(0.15, 0.18),
        legend.title = element_blank()
        ) 


setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("normalizedmeansummary_viz.pdf",width = 7, height = 4)
normalizedmeansummary_viz
dev.off()

if(any(grepl("package:plyr", search()))) detach("package:plyr") else message("plyr not loaded")
library(dplyr)
```

```{r message=FALSE,warning=FALSE}
projectsummary_viz
projectsummarynormalized_viz
```

```{r message=FALSE,warning=FALSE}
meansummary_viz
normalizedmeansummary_viz
```

### Project Cosine Similarity
```{r , echo=FALSE,message=FALSE,warning=FALSE,cache=TRUE}
cosine_summary <- usersummarydata[,c(1,2,7,9)]

library(plyr)
tgc3 <- summarySE(cosine_summary, measurevar="cosine_similarity", groupvars=c("project","month"))

project_cosine <- ggplot(subset(tgc3, month !=1), aes(x=month, 
                                        y=cosine_similarity,group=project, 
                                        colour=project)) +
  #geom_line(aes(linetype=project))  + 
  geom_smooth() +
  scale_color_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + theme_minimal() + 
  labs(x = "Project Month", y=expression(~Cosine~Score~(mu))) +
  theme_classic() + theme_minimal() + 
  theme(axis.text.y = element_text(size=14), 
        axis.text.x = element_text(size=12),
        axis.title = element_text(size=14), 
        legend.position = c(.8, 0.8),
        legend.title = element_blank(),
        strip.text = element_text(size = 10))

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("projectcosine.pdf",width = 7, height = 4)
project_cosine
dev.off()
```

```{r message=FALSE,warning=FALSE}
project_cosine
```

## Volunteer Linguistic Trajectories
In this section, we examined the trends in cosine similarity scores.

### Cosine Simlarity Score
```{r , echo=FALSE,message=FALSE,warning=FALSE,cache=TRUE}
normcosine_summary <- usersummarydata[,c(1,8,7,9)]

tgc4 <- summarySE(normcosine_summary, measurevar="cosine_similarity", groupvars=c("project","normmonthpost"))

user_cosine <- ggplot(tgc4, aes(x=normmonthpost, 
                                        y=cosine_similarity,group=project, 
                                        colour=project)) +
  #geom_line(aes(linetype=project))  + 
  geom_smooth() +
  scale_color_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + theme_minimal() + 
  labs(x = "User Month", y=expression(~Cosine~Score~(mu))) +
  theme_classic() + theme_minimal() + 
  theme(axis.text.y = element_text(size=14), 
        axis.text.x = element_text(size=12),
        axis.title = element_text(size=14), 
        legend.position = c(.8, 0.2),
        legend.title = element_blank(),
        strip.text = element_text(size = 10))

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("usercosine.pdf",width = 7, height = 4)
user_cosine
dev.off()

if(any(grepl("package:plyr", search()))) detach("package:plyr") else message("plyr not loaded")
library(dplyr)
```

```{r message=FALSE,warning=FALSE}
user_cosine
```

### Modeling the Similarity Score

#### The Viewing Behaviors of Gravity Spy Volunteers 
```{r , echo=FALSE,message=FALSE,warning=FALSE,cache=TRUE}
# Gs viewing behaviors and modeling
if(any(grepl("package:plyr", search()))) detach("package:plyr") else message("plyr not loaded")
library(dplyr)

view_summary <- geordi_views %>% 
  group_by(month=floor_date(time, "month")) %>% 
  summarize(total_views=length(userID),                                                     total_users=length(unique(userID))
           )

view_summary_user <- geordi_views %>% 
  group_by(userID) %>% 
  summarize(total_views=length(userID),                                                  
            first_view = min(floor_date(time, "month")),
             months_viewing = length(unique(floor_date(time, "month")))
           )

view_month_user <- geordi_views %>% 
  group_by(userID,month=floor_date(time, "month")) %>% 
  summarize(total_views=length(userID))

library(plyr)
tgc5 <- summarySE(view_month_user, measurevar="total_views", groupvars=c("month"))

# cosine over project lifespan
project_gsviews <- ggplot(tgc5, aes(x=as.Date(month), y=total_views)) + 
  geom_bar(stat="identity", color="black", 
           position=position_dodge()) +
  geom_point()+
  scale_x_date(date_labels="%b %y",date_breaks  ="1 month") +
  geom_errorbar(aes(ymin=total_views-se, ymax=total_views+se), width=.2,
                 position=position_dodge(0.05)) + 
  labs(x = "Project Month",y=expression(~Page~Views~(mu))) +
  theme_classic() + theme_minimal() + 
  theme(axis.text.y = element_text(size=14,face="bold"), 
        axis.text.x = element_text(angle=90,size=12,face="bold"),
        axis.title.y = element_text(face="bold"), 
        axis.title = element_text(size=14,face="bold"), 
        legend.text=element_text(size=11),
        strip.text = element_text(size = 10))

# export figure
setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("gs_views.pdf",width = 7, height = 4)
project_gsviews
dev.off()

# viewing over month by user
# add user sequence variable so we see month/comment over score change
view_month_user <- as.data.table(view_month_user)
view_month_user[, normmonthview := sequence(.N), by = c("userID")]
view_month_user <- as.data.frame(view_month_user)

library(plyr)
tgc6 <- summarySE(view_month_user, measurevar="total_views", groupvars=c("normmonthview"))
tgc6$normmonthview <- as.numeric(tgc6$normmonthview)

project_gsuserview <- ggplot(subset(tgc6,normmonthview <=20), aes(x=as.factor(normmonthview), y=total_views)) + 
  geom_bar(stat="identity", color="black", 
           position=position_dodge()) +
  geom_point()+
  geom_errorbar(aes(ymin=total_views-se, ymax=total_views+se), width=.2,
                 position=position_dodge(0.05)) + 
  labs(x = "User Month", y=expression(~Page~Views~(mu))) +
  theme_classic() + theme_minimal() + 
  theme(axis.text.y = element_text(size=14,face="bold"), 
        axis.text.x = element_text(size=12,face="bold"),
        axis.title.y = element_text(face="bold"), 
        axis.title = element_text(size=14,face="bold"), 
        legend.text=element_text(size=11),
        strip.text = element_text(size = 10))

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("gs_userview.pdf",width = 7, height = 4)
project_gsuserview
dev.off()

if(any(grepl("package:plyr", search()))) detach("package:plyr") else message("plyr not loaded")
library(dplyr)
```

```{r message=FALSE,warning=FALSE}
project_gsviews
```

```{r message=FALSE,warning=FALSE}
project_gsuserview
```

#### Modeling linguistic similarity
```{r , echo=FALSE,message=FALSE,warning=FALSE}
# munging to prepare to regression analysis. Report three models (1) incl. GS viewing behaviors (2) GS cosine (3) SS cosine

#### (1) modeling for GS after month 6 to include geordi data

########################################
#### (1) modeling for GS with views ####
########################################

#add months to cosine gs data
gsmonth_cosine2 <- merge(gsmonth_cosine2,gsmonths, 
                         by.x=c("month"), 
                         by.y=c("num"),
                         all.x=TRUE)
names(gsmonth_cosine2)[9] <- "project_month"

# combined view data
combined_data <- merge(gsmonth_cosine2,view_month_user, 
                       by.x=c("comment_user_id","project_month"),
                       by.y=c("userID","month"), 
                       all.x=TRUE)

# Geordi didn't start collecting views until month project month 5 or 2016-07-01 so remove data before this time
combined_data <- combined_data[which(!is.na(combined_data$total_views)),]

names(combined_data) <- c("comment_user_id","project_month_date","project_month","comment_user_login","comments","unigrams","unique_unigrams","newunigrams","cosine_similarity","total_views","user_view_month") # change column names
remove(gsmonth_cosine2)

#### linear regression model
gsview_cosine.lm <- lm(cosine_similarity~ project_month+comments+unigrams+unique_unigrams+newunigrams+total_views, data = combined_data)

####  panel regression model 

#https://www.econometrics-with-r.org/10-rwpd.html 
#A log transformation for each variable. 
#Posts as a threshold or binning since some people only post a handful of occasions
#Keeping up with the times sliding window of terminology 
#https://cran.r-project.org/web/packages/plm/vignettes/plmPackage.html

gsview_cosine.panel <- plm(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams+total_views,
                    data = combined_data,
                    index = c("comment_user_login"), # look over levels
                    model = "within",
                    effect="individual")
#coeftest(cosine.panel.lm, vcov. = vcovHC, type = "HC1")

####  mixed effects 
gsview_cosine.lmer <- lmer(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams+total_views
                     + (1 | comment_user_id), data = combined_data, REML=F)

#############################
#### (2) modeling for GS ####
#############################

names(gsmonth_cosine) <- c("user_name","project_month","comments","unigrams","unique_unigrams","newunigrams","cosine_similarity","normalizedpostmonth","project") # change column names

#### linear regression model
gscosine.lm <- lm(cosine_similarity~ project_month+comments+unigrams+unique_unigrams+newunigrams, data = gsmonth_cosine)

####  panel regression model 
gscosine.panel <- plm(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams,
                    data = gsmonth_cosine,
                    index = c("user_name"), # look over levels
                    model = "within",
                    effect="individual")

####  mixed effects 
gscosine.lmer <- lmer(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams
                     + (1 | user_name), data = gsmonth_cosine, REML=F)

#############################
#### (3) modeling for SS ####
#############################
names(ssmonth_cosine) <- c("user_name","project_month","comments","unigrams","unique_unigrams","newunigrams","cosine_similarity","normalizedpostmonth","project") # change column names

#### linear regression model
sscosine.lm <- lm(cosine_similarity~ project_month+comments+unigrams+unique_unigrams+newunigrams, data = ssmonth_cosine)

####  panel regression model 
sscosine.panel <- plm(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams,
                    data = ssmonth_cosine,
                    index = c("user_name"), # look over levels
                    model = "within",
                    effect="individual")

####  mixed effects 
sscosine.lmer <- lmer(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams
                     + (1 | user_name), data = ssmonth_cosine, REML=F)
```

##### Linear Regression
```{r, results = "asis"}
# Report three models (1) incl. GS viewing behaviors (2) GS cosine (3) SS cosine
stargazer(gsview_cosine.lm,gscosine.lm,sscosine.lm,
          star.cutoffs = c(0.05, 0.01, 0.001), 
          dep.var.labels=c("Cosine Similarity"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
           digits=3
)
```

##### Panel Regression
```{r, results = "asis"}
# Report three models (1) incl. GS viewing behaviors (2) GS cosine (3) SS cosine
stargazer(gsview_cosine.panel,gscosine.panel,sscosine.panel,
          star.cutoffs = c(0.05, 0.01, 0.001), 
          dep.var.labels=c("Cosine Similarity"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
           digits=3
)
```

##### Mixed-Effects Regression
```{r, results = "asis"}
# Report three models (1) incl. GS viewing behaviors (2) GS cosine (3) SS cosine
stargazer(gsview_cosine.lmer,gscosine.lmer,sscosine.lmer,
          star.cutoffs = c(0.05, 0.01, 0.001), 
          dep.var.labels=c("Cosine Similarity"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
           digits=3
)
```

## Newcomer Linguistic Competencies

### Cohort-based Simlarity for Newcomers
```{r , echo=FALSE,message=FALSE,warning=FALSE}

newcomer_cosine <- usersummarydata[which(usersummarydata$normmonthpost==1),]
newcomer_cosine_summary <- summarySE(newcomer_cosine, measurevar="cosine_similarity", groupvars=c("project","month"))

newcomer_cosine_summary <- newcomer_cosine_summary[which(!(newcomer_cosine_summary$project== "Gravity Spy" & newcomer_cosine_summary$month == 1)),] # remove GS first month since only one user

# cohort based look at cosine similarity
newcomer_cosine_viz <- ggplot(newcomer_cosine_summary, aes(x=month, 
                                        y=cosine_similarity,group=project, 
                                        colour=project)) +
  #geom_line(aes(linetype=project))  + 
  geom_smooth() +
  scale_color_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + theme_minimal() + 
  labs(x = "Project Month", y=expression(~Cosine~Score~(mu))) +
  theme_classic() + theme_minimal() + 
  theme(axis.text.y = element_text(size=14), 
        axis.text.x = element_text(size=12),
        axis.title = element_text(size=14), 
        legend.position = c(.8, 0.7),
        legend.title = element_blank(),
        strip.text = element_text(size = 10))

setwd("~/Dropbox/INSPIRE/Papers & Presentations/Language Socialization (CSCW 2020)/Figures2/")
pdf("newcomer_cosine_viz.pdf",width = 7, height = 4)
newcomer_cosine_viz
dev.off()
```

```{r}
newcomer_cosine_viz
```

```{r , echo=FALSE,message=FALSE,warning=FALSE}
names(newcomer_cosine) <- c("user_name","project_month","comments","unigrams","unique_unigrams","newunigrams","cosine_similarity","normalizedpostmonth","project") # change column names

#############################
#### (1) Newcomer for GS ####
#############################
newcomer_cosinegs <- newcomer_cosine[which(newcomer_cosine$project=="Gravity Spy"),]

#### linear regression model
gsnewcomer.lm <- lm(cosine_similarity~ project_month+comments+unigrams+unique_unigrams+newunigrams, data = newcomer_cosinegs)

####  panel regression model 
gsnewcomer.panel <- plm(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams,
                    data = newcomer_cosinegs,
                    index = c("project_month"), # look over levels
                    model = "within",
                    effect="individual")

####  mixed effects 
gsnewcomer.lmer <- lmer(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams
                     + (1 | project_month), data = newcomer_cosinegs, REML=F)

#############################
#### (2) Newcomer for SS ####
#############################
newcomer_cosiness <- newcomer_cosine[which(newcomer_cosine$project=="Snapshot Serengeti"),]


#### linear regression model
ssnewcomer.lm <- lm(cosine_similarity~ project_month+comments+unigrams+unique_unigrams+newunigrams, data = newcomer_cosiness)

####  panel regression model 
ssnewcomer.panel <- plm(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams,
                    data = newcomer_cosiness,
                    index = c("project_month"), # look over levels
                    model = "within",
                    effect="individual")

####  mixed effects 
ssnewcomer.lmer <- lmer(cosine_similarity~ 
                    project_month+comments+unigrams+unique_unigrams+newunigrams
                     + (1 | project_month), data = newcomer_cosiness, REML=F)

```

##### Linear Regression
```{r, results = "asis"}
# Report three models (1) incl. GS viewing behaviors (2) GS cosine (3) SS cosine
stargazer(gsnewcomer.lm,ssnewcomer.lm,
          star.cutoffs = c(0.05, 0.01, 0.001), 
          dep.var.labels=c("Cosine Similarity"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
           digits=3
)
```

##### Panel Regression
```{r, results = "asis"}
# Report three models (1) incl. GS viewing behaviors (2) GS cosine (3) SS cosine
stargazer(gsnewcomer.panel,ssnewcomer.panel,
          star.cutoffs = c(0.05, 0.01, 0.001), 
          dep.var.labels=c("Cosine Similarity"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
           digits=3
)
```

##### Mixed-Effects Regression
```{r, results = "asis"}
# Report three models (1) incl. GS viewing behaviors (2) GS cosine (3) SS cosine
stargazer(gsnewcomer.lmer,ssnewcomer.lmer,
          star.cutoffs = c(0.05, 0.01, 0.001), 
          dep.var.labels=c("Cosine Similarity"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
           digits=3
)
```
