---
title: "Language_Analysis"
output:
  html_document: default
  pdf_document: default
date: "2022-09-08"
---

```{r, echo=FALSE, include=FALSE, warning=FALSE}
# rmarkdown::render("frget.Rmd")
# Libraries Needed
library(reshape2)
library(hrbrthemes)
library(scales)
library(ggsci)
library(data.table)
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(lubridate)
library(lme4)
library(nlme)
library(stargazer)
library(caret)
library(rcompanion)
library(tm)
library(performance)
library(tidytext)
#Functions
logit2prob <- function(logit){
  odds <- exp(logit)
  prob <- odds / (1 + odds)
  return(prob)
}

stargazer2 <- function(model, odd.ratio = F, ...) {
  if(!("list" %in% class(model))) model <- list(model)
    
  if (odd.ratio) {
    coefOR2 <- lapply(model, function(x) exp(coef(x)))
    seOR2 <- lapply(model, function(x) exp(coef(x)) * summary(x)$coef[, 2])
    p2 <- lapply(model, function(x) summary(x)$coefficients[, 4])
    stargazer(model, coef = coefOR2, se = seOR2, p = p2, ...)
    
  } else {
    stargazer(model, ...)
  }
}
launch_date <- as.POSIXct("2016-10-12 12:00:00",  format="%Y-%m-%d %H:%M:%S")


newcomers_data <- read_csv("/Volumes/cbjackson2/language models/newcomer_info.csv")
newcomers_data <- newcomers_data[,-1]
newcomers_week_data <-  read_csv("/Volumes/cbjackson2/language models/newcomer_week_info.csv") 
newcomers_week_data <- data.frame(newcomers_week_data)
newcomers_week_data$week <- as.Date(newcomers_week_data$week)
newcomers_week_data$user_id <- as.factor(newcomers_week_data$user_id)
comments <- read_csv("/Volumes/cbjackson2/language models/comments_newcomer_add.csv") 

# Add newcomer comment features to newcomers_data
comments <- merge(comments,newcomers_data[,c("user_id","join_date")],by.y="user_id",by.x = "comment_user_id",all.x = TRUE)


comments$include <- ifelse(comments$comment_created_at <= add_with_rollback(comments$join_date, months(3), roll_to_first = TRUE),1,0)
comments <- comments[which(comments$include==1),]

comment_summary <- comments %>% 
  group_by(user_id=comment_user_id) %>%
  summarise(comment_no=length(comment_id),
            questions = sum(questions),
            replies = sum(replies),
            links = sum(links),
            words = sum(words)
  )


comment_week_summary <- comments %>% 
  group_by(user_id=as.factor(comment_user_id), week=floor_date(created_at, "week")) %>%
  summarise(comment_no=length(comment_id),
            questions = sum(questions),
            replies = sum(replies),
            links = sum(links),
            words = sum(words)
  )
comment_week_summary <- data.frame(comment_week_summary)
comment_week_summary <- comment_week_summary[order(comment_week_summary$user_id,comment_week_summary$week),]
comment_week_summary <- as.data.table(comment_week_summary)[, comment_week := 1:.N,, by = list(user_id)] 
comment_week_summary <- data.frame(comment_week_summary)
 
newcomers_data <- merge(newcomers_data,comment_summary, by="user_id",all.x = TRUE)
newcomers_data$since_start <- round(as.numeric(difftime(newcomers_data$join_date,launch_date,units = "days")),digits = 0)
newcomers_data_org <- newcomers_data
remove(comment_summary)

#newcomers_data <- newcomers_data[which(newcomers_data$join_date >= as.Date(launch_date)),] # removed 1096 users who were around prior to launch

### Build Cosine dataset
domain_cosine <- read_csv("/Volumes/cbjackson2/language models/cosine_domain.csv") 
names(domain_cosine)[c(4,8)] <- c("domain_cosine","domain_change")
science_cosine <- read_csv("/Volumes/cbjackson2/language models/cosine_science.csv") 

cosine <- merge(domain_cosine,science_cosine, by=c("user_id","variable"))
cosine <- cosine[,c(1,2,4,8,5,6,7,10,14)]
names(cosine)[c(5:9)] <- c("real_week","comment_week","last_session","science_cosine","science_change")

# Get only newcomer cosine information
newcomers_period <-  newcomers_data[,c(1,9)]

cosine <- merge(cosine,newcomers_period,by="user_id")
cosine <- cosine[which(cosine$comment_week <= cosine$newcomer_comment_weeks),]

newcomers_week_data <- merge(newcomers_week_data,comment_week_summary,by=c("user_id","week"),all.x=TRUE)
newcomers_week_data <- merge(newcomers_week_data,cosine,by.x=c("user_id","user_week"),by.y=c("user_id","real_week"),all.x=TRUE)
newcomers_week_data <- newcomers_week_data[which(newcomers_week_data$user_id %in% newcomers_data$user_id),]
newcomers_week_data <- newcomers_week_data[which(newcomers_week_data$user_week<=12 & !is.na(newcomers_week_data$comment_no)),]

newcomers_data <- merge(newcomers_data,cosine[,c("user_id","domain_cosine","science_cosine","comment_week")],
                                  by.x=c("user_id","newcomer_comment_weeks"),by.y = c("user_id","comment_week"))

newcomers_data$Class <- as.factor(newcomers_data$retained)

## SOME USERS ACTUALLY HAVE COMMENTS DURING WEEKS BUT NOT STATS. PERHAPS ISSUE WITH PREVIOUS COMPUTATION OF CREATED_AT and TZ ISSUE
```

```{r, eval=FALSE}
# Import words


ggplot(data=word_use, aes(x=as.Date(firstuse))) + 
                  #geom_line(stat="bin",size=.7,color="#56B4E9") + 
  geom_smooth(stat="bin",size=.7,color="#56B4E9") +
    labs(x="Month",y="New Terms") + 
  scale_x_date(date_labels="%b %y",date_breaks  ="2 month") + theme_classic() +  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position="bottom", legend.title = element_blank()) + 
geom_vline(aes(xintercept=as.Date("2016-10-01")),linetype="dashed", color = "grey22",size=.7)

```



```{r, allusersmodels, echo=FALSE, include=FALSE, warning=FALSE}

# Perhaps zero-inflated (https://stats.oarc.ucla.edu/r/dae/zip/)
# logistic for adoption (https://rpubs.com/OmaymaS/182726)
trainIndex_down <- createDataPartition(newcomers_data$Class, p = .7,
                                  list = FALSE,
                                  times = 1)
train_down <- newcomers_data[ trainIndex_down,]
valid_down <- newcomers_data[-trainIndex_down,]

# ~2900 retained and ~16k dropout

# Since the data are unbalanced, we need to implement a subsampling method - upsampling, downsampling, or a hybrid method e.g. ROSE, SMOTE. 

### Downsampling
# traindown <-downSample(x=train_down[,-ncol(train_down)],
#                   y=train_down$Class)
# 
# # Both classes are equal
# set.seed(23243)
# retentiondown.glm <- glm(Class ~ newcomer_class+newcomer_comment+newcomer_sessions+since_start, data = traindown, family="binomial") # MODEL
# 
# logit2prob(coef(retentiondown.glm)) #coefficients
# nagelkerke(retentiondown.glm) # performance measures
# 
# predict.down <- predict(retentiondown.glm , newdata = valid_down, type = 'response')
# predict.down <- as.integer(predict.down>0.5)
# confusionMatrix(as.factor(predict.down),valid_down$Class)


### Upsampling
trainIndex_up <- createDataPartition(newcomers_data$Class, p = .7,
                                  list = FALSE,
                                  times = 1)
train_up <- newcomers_data[ trainIndex_up,]
valid_up <- newcomers_data[-trainIndex_up,]


trainup<-upSample(x=train_up[,-ncol(train_up)],
                  y=train_up$Class)

# Both classes are equal
retentionup.glm <- glm(Class ~ newcomer_class+newcomer_comment+newcomer_sessions+since_start, data = trainup, family="binomial") # MODEL
```

```{r, commentersmodels, echo=FALSE, include=FALSE, warning=FALSE}
################################
#   COMMENTERS MODELS          #
################################

##### UPSAMPLING
# Get only users who actually commented during the newcomer period
newcomer_info_commenters <- newcomers_data[which(newcomers_data$newcomer_comment>=1),]
newcomer_info_commenters <- newcomer_info_commenters[which(newcomer_info_commenters$newcomer_weeks >= 2 & newcomer_info_commenters$newcomer_comment>=1),] #1407

trainIndex_commenter <- createDataPartition(newcomer_info_commenters$Class, p = .7,
                                  list = FALSE,
                                  times = 1)
train_commenter_up <- newcomer_info_commenters[ trainIndex_commenter,]
valid_commenter_up <- newcomer_info_commenters[-trainIndex_commenter,]

traincommenterup<-upSample(x=train_commenter_up[,-ncol(train_commenter_up)],
                  y=train_commenter_up$Class)

retention_commentersup.glm <- glm(Class ~ newcomer_class+newcomer_comment+newcomer_sessions+newcomer_first_comment_seq+dslope+sslope+domain_cosine+science_cosine+questions+links+words+since_start+newcomer_first_comment_ses,data = traincommenterup,family="binomial")

##### DOWNSAMPLING
# trainIndex_commenter <- createDataPartition(newcomer_info_commenters$Class, p = .7,
#                                   list = FALSE,
#                                   times = 1)
# train_commenter_down <- newcomer_info_commenters[ trainIndex_commenter,]
# valid_commenter_down <- newcomer_info_commenters[-trainIndex_commenter,]
# 
# traincommenterdown <-upSample(x=train_commenter_down[,-ncol(train_commenter_down)],y=train_commenter_down$Class)
# 
# retention_commentersdown.glm <- glm(Class ~ newcomer_class+newcomer_comment+newcomer_sessions+newcomer_first_comment_seq+dslope+sslope+cosine_domain+cosine_science+questions+links+words+since_start+newcomer_first_comment_ses,data = traincommenterdown,family="binomial")
# 
# logit2prob(coef(retention_commentersdown.glm)) #coefficients
# nagelkerke(retention_commentersdown.glm) # performance measures
# 
# predictcommenter.down <- predict(retention_commentersdown.glm , newdata = valid_commenter_down, type = 'response')
# predictcommenter.down <- as.integer(predictcommenter.down>0.5)
# confusionMatrix(as.factor(predictcommenter.down),valid_commenter_down$Class)

# https://easystats.github.io/performance/ 
week_model <- newcomers_week_data[which(!is.na(newcomers_week_data$variable)),]
week_model$week_class <- log(week_model$week_class+1)
names(week_model)[15] <- "comment_week"
week_model$comment_week <- as.factor(week_model$comment_week)

domain_model.lme <- lme(domain_cosine ~ week_class +week_comment + questions + links + words + last_session , random = ~ 1|user_id, data = week_model,method = "REML")

domain_modelchange.lme <- lme(domain_change ~ week_class +week_comment + questions + links + words + last_session , random = ~ 1|user_id, data = week_model,method = "REML")


domain_model.lmer <- lmer(domain_cosine ~ week_class +week_comment + questions + links + words + last_session + (1|user_id), data = week_model,REML=FALSE)

domain_modelchange.lmer <- lmer(domain_change ~ week_class +week_comment + questions + links + words + last_session + (1|user_id), data = week_model,REML=FALSE)

science_model.lme <- lme(science_cosine ~ week_class +week_comment + questions + links + words + last_session, random = ~ 1|user_id, data = week_model,method = "REML")

science_modelchange.lme <- lme(science_change ~ week_class +week_comment + questions + links + words + last_session, random = ~ 1|user_id, data = week_model,method = "REML")


science_model.lmer <- lmer(science_cosine ~ week_class +week_comment + questions + links + words + last_session + (1|user_id), data = week_model,REML=FALSE)

science_modelchange.lmer <- lmer(science_change ~ week_class +week_comment + questions + links + words + last_session + (1|user_id), data = week_model,REML=FALSE)
#OUTCOMES ARE EXACTLY THE SAME
```

## Retention models
```{r mixedmodel2, results = "asis", echo=TRUE, include=TRUE}
stargazer(retentionup.glm, retention_commentersup.glm, title="Retention Models",star.cutoffs = c(0.05, 0.01, 0.001), dep.var.labels=c("Retained (=1)"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
          t.auto=F, p.auto=F, 
          report = "vc*",
           digits=3
          
) #covariate.labels=c("Agent Centered","Authority Subject","Communal")
```

### All retention performance 
```{r}
logit2prob(coef(retentionup.glm)) #coefficients
nagelkerke(retentionup.glm) # performance measures

predict.up <- predict(retentionup.glm , newdata = valid_up, type = 'response')
predict.up <- as.integer(predict.up>0.5)
confusionMatrix(as.factor(predict.up),valid_up$Class)
```

### Commnter retention performance
```{r}
################################
#   COMMENTERS MODELS          #
################################

##### UPSAMPLING

# Get only users who actually commented during the newcomer period

newcomer_info_commenters <- newcomers_data[which(newcomers_data$newcomer_comment>=1),]
newcomer_info_commenters <- newcomer_info_commenters[which(newcomer_info_commenters$newcomer_weeks >= 2 & newcomer_info_commenters$newcomer_comment>=1),] #1407



trainIndex_commenter <- createDataPartition(newcomer_info_commenters$Class, p = .7,
                                  list = FALSE,
                                  times = 1)
train_commenter_up <- newcomer_info_commenters[ trainIndex_commenter,]
valid_commenter_up <- newcomer_info_commenters[-trainIndex_commenter,]


traincommenterup<-upSample(x=train_commenter_up[,-ncol(train_commenter_up)],
                  y=train_commenter_up$Class)

retention_commentersup.glm <- glm(Class ~ newcomer_class+newcomer_comment+newcomer_sessions+newcomer_first_comment_seq+dslope+sslope+domain_cosine+science_cosine+questions+links+words+since_start+newcomer_first_comment_ses,data = traincommenterup,family="binomial")

logit2prob(coef(retention_commentersup.glm)) #coefficients
nagelkerke(retention_commentersup.glm) # performance measures

predictcommenter.up <- predict(retention_commentersup.glm , newdata = valid_commenter_up, type = 'response')
predictcommenter.up <- as.integer(predictcommenter.up>0.5)
confusionMatrix(as.factor(predictcommenter.up),valid_commenter_up$Class)
```

```{r }
trainIndex_commenter <- createDataPartition(newcomer_info_commenters$Class, p = .7,
                                  list = FALSE,
                                  times = 1)
train_commenter_down <- newcomer_info_commenters[ trainIndex_commenter,]
valid_commenter_down <- newcomer_info_commenters[-trainIndex_commenter,]

traincommenterdown<-upSample(x=train_commenter_down[,-ncol(train_commenter_down)],y=train_commenter_down$Class)

retention_commentersdown.glm <- glm(Class ~ newcomer_class+newcomer_comment+newcomer_sessions+newcomer_first_comment_seq+dslope+sslope+domain_cosine+science_cosine+questions+links+words+since_start+newcomer_first_comment_ses,data = traincommenterdown,family="binomial")

logit2prob(coef(retention_commentersdown.glm)) #coefficients
nagelkerke(retention_commentersdown.glm) # performance measures

predictcommenter.down <- predict(retention_commentersdown.glm , newdata = valid_commenter_down, type = 'response')
predictcommenter.down <- as.integer(predictcommenter.down>0.5)
confusionMatrix(as.factor(predictcommenter.down),valid_commenter_down$Class)

### SIMILARITY MODEL
week_model <- newcomers_week_data[which(!is.na(newcomers_week_data$variable)),]
#Similarity = number of session + days since start  + classifications + comments + gap( difference between current and previous week + (1|user_id)
```


```{r mixedmodel3, results = "asis", echo=TRUE, include=TRUE}
## Cosine models

stargazer(domain_model.lmer,science_model.lmer, title="Similarity Models (lmer)",star.cutoffs = c(0.05, 0.01, 0.001),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
          t.auto=F, p.auto=F, 
          report = "vc*",
           digits=3
          
) #covariate.labels=c("Agent Centered","Authority Subject","Communal")

```


```{r mixedmodel4, results = "asis", echo=TRUE, include=TRUE}
stargazer(domain_model.lme,science_model.lme, title="Similarity Models (lme)",star.cutoffs = c(0.05, 0.01, 0.001),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          omit.stat=c("f", "ser"),
          column.sep.width = "-8pt",
          type = "html",
          t.auto=F, p.auto=F, 
          report = "vc*",
           digits=3
          
) 
```
### Science cosine model

### Domain cosine model




