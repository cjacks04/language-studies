---
title: "Language_Analysis"
output:
  word_document: default
  html_document: default
  pdf_document: default
date: "2022-09-08"
---

```{r, echo=FALSE, include=FALSE, warning=FALSE}
# Libraries Needed
library(reshape2)
library(hrbrthemes)
library(scales)
library(ggsci)
library(data.table)
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(lubridate)
library(lme4)
library(nlme)
library(stargazer)
library(caret)
library(rcompanion)
library(tm)
library(performance)
library(tidytext)
library(gridExtra)
library(trend)

#Functions
logit2prob <- function(logit){
  odds <- exp(logit)
  prob <- odds / (1 + odds)
  return(prob)
}

data_summary <- function(data, varname, groupnames){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      sd = sd(x[[col]], na.rm=TRUE))
  }
  data_sum<-ddply(data, groupnames, .fun=summary_func,
                  varname)
  data_sum <- rename(data_sum, c("mean" = varname))
 return(data_sum)
}

stargazer2 <- function(model, odd.ratio = F, ...) {
  if(!("list" %in% class(model))) model <- list(model)
    
  if (odd.ratio) {
    coefOR2 <- lapply(model, function(x) exp(coef(x)))
    seOR2 <- lapply(model, function(x) exp(coef(x)) * summary(x)$coef[, 2])
    p2 <- lapply(model, function(x) summary(x)$coefficients[, 4])
    stargazer(model, coef = coefOR2, se = seOR2, p = p2, ...)
    
  } else {
    stargazer(model, ...)
  }
}
launch_date <- as.POSIXct("2016-10-12 12:00:00",  format="%Y-%m-%d %H:%M:%S")

# Import words
domain <- read.table("/Volumes/cbjackson2/language models/domain_clean.txt", quote="\"", comment.char="")
domain <- c(domain$x)

field <- read.table("/Volumes/cbjackson2/language models/science_clean.txt", quote="\"", comment.char="")
field <- c(field$x)
```


```{r project-growth, echo=FALSE}

# How the project grows over time
all_comments <- read_csv("/Volumes/cbjackson2/language models/comments_newcomer_add.csv") # All project comments
all_comments <- all_comments[,-c(1:4)]

# Add summaries
all_comments$tags <- stringr::str_count(all_comments$comment_body, "\\#") 
all_comments$user_references <- stringr::str_count(all_comments$comment_body, "\\@") 
all_comments$questions <- stringr::str_count(all_comments$comment_body, "\\?") 
all_comments$domain_words <- stringr::str_count(all_comments$comment_body, paste(domain, collapse='|'))
all_comments$field_words <- stringr::str_count(all_comments$comment_body, paste(field, collapse='|'))
 
# Compute power laws https://cran.r-project.org/web/packages/poweRlaw/vignettes/b_powerlaw_examples.pdf and https://towardsdatascience.com/analysing-power-law-distributions-with-r-4312c7b4261b 
############################################################
############################################################
############################################################
# COMMENTS 

all_comments_summary <- all_comments  %>%  
  group_by(week=floor_date(comment_created_at, "week")) %>% 
  summarize(comment_count =length(comment_id)) %>%
  mutate(
         comment_growth = cumsum(comment_count),
         comment_pct = cumsum(comment_count)/sum(comment_count),
         comment_diff_growth = comment_pct - lag(comment_pct))

############################################################
############################################################
############################################################
# WORDS 

all_words <- data.frame(read_csv("/Volumes/cbjackson2/language models/worddata/word_first_use.csv")) # A
all_words_summary <- all_words  %>%  
  group_by(week=floor_date(firstuse, "week")) %>% 
  summarize(word_count =length(unigram)) %>%
  mutate(
         word_growth = cumsum(word_count),
         word_pct = cumsum(word_count)/sum(word_count),
         word_diff_growth = word_pct - lag(word_pct))

### Get growth in field and domain words
all_words$type <- ifelse(all_words$unigram %in% field,"Field",
                           ifelse(all_words$unigram %in% domain,"Domain","Regular"))


# A container is needed to compute since some weeks might not have new domain or field words
# Get all weeks 

weeks_s <- data.frame(all_comments_summary$week)
names(weeks_s)[1] <- "week"

domain_words_summary <- all_words  %>%  
  filter(type=="Domain") %>% 
  group_by(week=floor_date(firstuse, "week")) %>% 
  summarize(domain_count =length(unigram))

domain_words_summary <- merge(weeks_s,domain_words_summary, by = "week",all.x=TRUE)
domain_words_summary$domain_count[is.na(domain_words_summary$domain_count)] <- 0  #fill NA with 0 

domain_words_summary <- domain_words_summary  %>%  
   mutate(
         domain_growth = cumsum(domain_count),
         domain_pct = cumsum(domain_count)/sum(domain_count),
         domain_diff_growth = domain_pct - lag(domain_pct))

field_words_summary <- all_words  %>%  
  filter(type=="Field") %>% 
  group_by(week=floor_date(firstuse, "week")) %>% 
  summarize(field_count =length(unigram))

field_words_summary <- merge(weeks_s,field_words_summary, by = "week",all.x=TRUE)
field_words_summary$field_count[is.na(field_words_summary$field_count)] <- 0  #fill NA with 0 

field_words_summary <- field_words_summary  %>%  
   mutate(
         field_growth = cumsum(field_count),
         field_pct = cumsum(field_count)/sum(field_count),
         field_diff_growth = field_pct - lag(field_pct))

remove(weeks_s)
############################################################
############################################################
############################################################
# UNIGRAMS 
unigrams <- read_csv("/Volumes/cbjackson2/language models/worddata/unigram_comments.csv") # All unigrams
unigrams <- data.frame(unigrams)

all_token_summary <- unigrams  %>%  
  group_by(week=floor_date(comment_created_at, "week")) %>% 
  summarize(token_count =length(unigram)) %>%
  mutate(
         token_growth = cumsum(token_count),
         token_pct = cumsum(token_count)/sum(token_count),
         token_diff_growth = token_pct - lag(token_pct))

############################################################
############################################################
############################################################
# THREADS 

all_threads_summary <- all_comments  %>%  
  group_by(week=floor_date(comment_created_at, "week")) %>% 
  summarize(thread_count =length(unique(discussion_id))) %>%
  mutate(
         thread_growth = cumsum(thread_count),
         thread_pct = cumsum(thread_count)/sum(thread_count),
         thread_diff_growth = thread_pct - lag(thread_pct))


# Users introducing threads per week
thread_first <- all_comments %>% group_by(discussion_id)%>%
             summarize(
              thread_created_at = min(comment_created_at),
              starter = paste0(comment_user_id[which(thread_created_at==min(comment_created_at))],""),    
              )

thread_first_user <- thread_first  %>%  
  group_by(user_id = starter, week=floor_date(thread_created_at, "week")) %>% 
  summarize(threads_started = length(unique(discussion_id))) 


##### Merge data
eco_grow <- merge(all_comments_summary,all_words_summary, by="week", all.x = TRUE)
eco_grow <- merge(eco_grow,all_threads_summary, by="week", all.x = TRUE)
eco_grow <- merge(eco_grow,all_token_summary, by="week", all.x = TRUE)
eco_grow <- merge(eco_grow,domain_words_summary, by="week", all.x = TRUE)
eco_grow <- merge(eco_grow,field_words_summary, by="week", all.x = TRUE)

remove(all_comments_summary,all_words_summary,all_threads_summary,all_token_summary,domain_words_summary,field_words_summary)

####################  
####################  Visualize data (3x2) grid
####################  


### Visualizing aggregate growth
eco_grow_plot <- eco_grow[,c(1,3,7,11,15,19,23)] 
eco_grow_plot$week <- as.Date(eco_grow_plot$week)
eco_grow_plot.m <- melt(eco_grow_plot, id.vars="week")

eco_grow_plot.m$variable <-  recode(eco_grow_plot.m$variable, comment_growth = "Comments", word_growth = "New Tokens",thread_growth = "Threads", token_growth = "All Tokens",domain_growth = "Domain Tokens", field_growth = "Field Tokens")

feature_growth <- ggplot(eco_grow_plot.m, aes(week, value)) + 
  geom_line(size=1) + 
  geom_smooth(size=.7, color="grey") +
  labs(x="Date",y="Feature growth") + 
  scale_x_date(date_labels="%b %y",date_breaks  ="6 month") + 
  theme_classic() + scale_color_nejm() +
  #scale_y_continuous(labels = function(x) paste0(x*100, "%")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position="none", 
        legend.title = element_blank(),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 10, face="bold")) + 
  geom_vline(aes(xintercept=as.Date("2016-10-12")),size=.25) + 
  geom_text(aes(x=as.Date("2016-10-11"), label="", y=.50), colour="grey", angle=90, vjust = -1, text=element_text(size=2)) +
    facet_wrap(~variable, scales="free_y")


pdf("/Users/jackson/Library/CloudStorage/Box-Box/_research/language[collab]/feature_growth.pdf", width=11, height=4)
feature_growth
dev.off()

### Visualizing weekly contributions (counts)
eco_count_plot <- eco_grow[,c(1,2,6,10,14,18,22)] 
eco_count_plot$week <- as.Date(eco_count_plot$week)
eco_count_plot.m <- melt(eco_count_plot, id.vars="week")

eco_count_plot.m$variable <-  recode(eco_count_plot.m$variable, comment_count = "Comments", word_count = "New Tokens",thread_count = "Threads", token_count = "All Tokens",
                                    domain_count = "Domain Tokens", field_count = "Field Tokens")

feature_count <- ggplot(eco_count_plot.m, aes(week, value)) + 
  geom_point(linewidth=.1) + 
  geom_smooth(size=.7, color="grey") +
  labs(x="Date",y="Feature growth") + 
  scale_x_date(date_labels="%b %y",date_breaks  ="6 month") + 
  theme_linedraw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position="none", 
        legend.title = element_blank(),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 10, face="bold")) + 
  geom_vline(aes(xintercept=as.Date("2016-10-12")),size=.25) + 
  geom_text(aes(x=as.Date("2016-10-11"), label="", y=.50), colour="grey", angle=90, vjust = -1, text=element_text(size=2)) +
    facet_wrap(~variable, scales="free_y")


#pdf("/Users/jackson/Library/CloudStorage/Box-Box/_research/language[collab]/feature_count.pdf", width=11, height=4)
pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/feature_count.pdf", width=11, height=4)
feature_count
dev.off()

####################  
####################  Stat Analysis
####################  

##### Conduct pettit test (changepoint) https://rpubs.com/shirazipooya/Pettitt-Test on the number of values each day 
growth_pettit <- eco_count_plot.m %>% 
  group_by(variable) %>% 
  mutate(statistics = pettitt.test(value)$statistic,
         estimate = pettitt.test(value)$estimate,
         p_value = pettitt.test(value)$p.value,
         week = eco_count_plot.m[['week']][pettitt.test(value)$estimate]) %>% 
  distinct(variable,statistics,estimate,week,p_value)

##### Conduct growth models (answering ... which growth model describes content) https://rpubs.com/jaelison/200149 or #https://www.marinedatascience.co/blog/2019/09/28/comparison-of-change-point-detection-methods/

eco_growthpct_plot <- eco_grow[,c(1,5,9,13,17,21,25)] 
eco_growthpct_plot <- eco_growthpct_plot[which(eco_growthpct_plot$week > launch_date),] # remove after the launch
eco_growthpct_plot$week <- as.Date(eco_growthpct_plot$week)
eco_growthpct_plot.m <- melt(eco_growthpct_plot, id.vars="week")
eco_growthpct_plot.m$transformed <- eco_growthpct_plot.m$value*100


remove(unigrams,eco_count_plot,eco_count_plot.m,eco_grow_plot,eco_grow_plot.m)
```

```{r }

# #word_use <- read_csv("/Volumes/cbjackson2/language models/worddata/word_use_clean.csv") 
# For each newcomer (for modeling) can we include some measure of the community during each week? 

newcomers_data <- read_csv("/Volumes/cbjackson2/language models/newcomer_info.csv",show_col_types = FALSE)
newcomers_data <- newcomers_data[,-1]

testers <- newcomers_data$user_id[which(newcomers_data$join_date < launch_date)]
not_eligible <- newcomers_data$user_id[which(newcomers_data$join_date > max(all_comments$comment_created_at) - months(2))]

#remove people who are project management, science team, and before launch
project_team <- c("uber_pye","areeda","mzevin1","RF45","jrsmith02","sbc538","adamamiller","olipatane","smarttiz","jafeldt","mcoughlin","citizenscientist1994","cjackso3", "camallen","lmp579","sciencejedi","crowston","Carsten","jessiemcd","ejm553","srallen", "costerlu@syr.edu","lcalian","joeykey","matsoulina","trouille","zooniverse")

team <- unique(all_comments$comment_user_id[which(all_comments$comment_user_login %in% project_team)]) 

newcomers_data <- data.frame(newcomers_data)

newcomers_data <- newcomers_data[which(
  !newcomers_data$user_id %in% team & 
    !newcomers_data$user_id %in% testers & 
    !newcomers_data$user_id %in% not_eligible),]

population <- newcomers_data$user_id

newcomers_week_data <-  read_csv("/Volumes/cbjackson2/language models/newcomer_week_info.csv",show_col_types = FALSE) 
newcomers_week_data <- data.frame(newcomers_week_data)
newcomers_week_data$week <- as.Date(newcomers_week_data$week)
newcomers_week_data$user_id <- as.factor(newcomers_week_data$user_id)
newcomers_week_data <- newcomers_week_data[which(newcomers_week_data$user_id %in% population),]


newcomer_comments <- merge(all_comments,newcomers_data[,c("user_id","join_date")],by.y="user_id",by.x = "comment_user_id",all.x = TRUE)

###### CHANGE DATA TO VIEW

newcomer_comments$include <- ifelse(newcomer_comments$comment_created_at <= add_with_rollback(newcomer_comments$join_date, months(2), roll_to_first = TRUE),1,0)
newcomer_comments <- newcomer_comments[which(newcomer_comments$include==1),]
newcomer_comments <- newcomer_comments[which(newcomer_comments$comment_user_id %in% population),] # only eligible people

comment_summary <- newcomer_comments %>% 
  group_by(user_id=comment_user_id) %>%
  summarise(comment_no=length(comment_id),
            questions = sum(questions),
            replies = sum(replies),
            links = sum(links),
            words = sum(words),
            tags = sum(tags),
            user_references = sum(user_references),
            domain_words = sum(domain_words),
            field_words = sum(field_words)
  )

comment_week_summary <- newcomer_comments %>% 
  group_by(user_id=as.factor(comment_user_id), week=floor_date(created_at, "week")) %>%
  summarise(comment_no=length(comment_id),
            questions = sum(questions),
            replies = sum(replies),
            links = sum(links),
            words = sum(words),
            tags = sum(tags),
            user_references = sum(user_references),
            domain_words = sum(domain_words),
            field_words = sum(field_words)
  )

comment_week_summary <- data.frame(comment_week_summary)
comment_week_summary <- comment_week_summary[order(comment_week_summary$user_id,comment_week_summary$week),]
comment_week_summary <- as.data.table(comment_week_summary)[, comment_week := 1:.N,, by = list(user_id)] 
comment_week_summary <- data.frame(comment_week_summary)
 
newcomers_data <- merge(newcomers_data,comment_summary, by="user_id",all.x = TRUE)
newcomers_data_org <- newcomers_data
remove(comment_summary)

### Build Cosine dataset
domain_cosine <- read_csv("/Volumes/cbjackson2/language models/cosine_domain.csv",show_col_types = FALSE) 
names(domain_cosine)[c(4,8)] <- c("domain_cosine","domain_change")
science_cosine <- read_csv("/Volumes/cbjackson2/language models/cosine_science.csv",show_col_types = FALSE) 

cosine <- merge(domain_cosine,science_cosine, by=c("user_id","variable"))
cosine <- cosine[,c(1,2,4,8,5,6,7,10,14)]
names(cosine)[c(5:9)] <- c("real_week","comment_week","last_session","science_cosine","science_change")

# Get only newcomer cosine information
newcomers_period <-  newcomers_data[,c(1,9)]
cosine <- merge(cosine,newcomers_period,by="user_id")
cosine <- cosine[which(cosine$comment_week <= cosine$newcomer_comment_weeks),]

newcomers_week_data <- merge(newcomers_week_data,comment_week_summary,by=c("user_id","week"),all.x=TRUE)
newcomers_week_data <- merge(newcomers_week_data,cosine,by.x=c("user_id","user_week"),by.y=c("user_id","real_week"),all.x=TRUE)
newcomers_week_data <- newcomers_week_data[which(newcomers_week_data$user_id %in% newcomers_data$user_id),]
newcomers_week_data <- newcomers_week_data[which(newcomers_week_data$user_week<=12 & !is.na(newcomers_week_data$comment_no)),]

newcomers_data <- merge(newcomers_data,cosine[,c("user_id","domain_cosine","science_cosine","comment_week")], by.x=c("user_id","newcomer_comment_weeks"),by.y = c("user_id","comment_week"), all.x = TRUE) 
newcomers_data <- newcomers_data[which(newcomers_data$newcomer_comment>=1),] #208 have no cosine data

# lost 208 because no cosine data
newcomers_data$Class <- as.factor(newcomers_data$retained) # 2610 
newcomers_week_data <- newcomers_week_data[which(newcomers_week_data$user_id %in% newcomers_data$user_id),]

###### ANALYSIS OF COMMENTERS AND COSING newcomers_week_data  AND newcomers_data

# SANITY CHECK FOR 36787 
 
# Plot features
user_count_plot <- newcomers_week_data %>%
  group_by(user_week) %>%
  summarise_at(c("comment_no","questions","links","words","tags","user_references",
                 "domain_words","field_words","domain_cosine","domain_change",
                 "science_cosine","science_change"), mean, na.rm = TRUE) 
  
user_count_plot.bar <- newcomers_week_data %>%
  select("user_week","comment_no","questions","links","words","tags","user_references",
                 "domain_words","field_words","domain_cosine","domain_change",
                 "science_cosine","science_change") 

user_count_plot.sum <- melt(user_count_plot.bar, id.vars="user_week")


user_count_plot.summary <- data_summary(user_count_plot.sum, varname=c("value"), 
                    groupnames=c("variable","user_week"))

user_count_plot.summary$variable <-  recode(user_count_plot.summary$variable, comment_no = "Comments", questions = "Questions",links = "URLs", words = "Tokens",tags = "Tags", user_references = "@s",domain_words = "Words(Field)",field_words = "Words(Astro)",science_change ="Change(Astro)",domain_change="Change(Field)",domain_cosine="Cosine(Field)",science_cosine="Cosine(Astro)")

user_count_plot.summary$user_week=as.factor(user_count_plot.summary$user_week)
user_count_plot.summary$variable <- factor(user_count_plot.summary$variable, 
                                            levels=c("Words(Field)", "Cosine(Field)", "Change(Field)",
                                                     "Words(Astro)", "Cosine(Astro)","Change(Astro)",
                                                     "Comments","Tokens","Tags","Questions","URLs","@s"))

## HIST
feature_commentB <- ggplot(subset(user_count_plot.summary, ! variable %in% c("Comments","Questions","URLs","Tokens","Tags","@s",NA)), aes(x=user_week, y=value)) + 
  geom_bar(stat="identity", color="black", 
           position=position_dodge()) +
  #geom_errorbar(aes(ymin=value, ymax=value+sd), width=.2,
                 #position=position_dodge(.9)) + 
  labs(x="Week",y="Use") + 
  theme_classic() + scale_color_nejm() +
  #scale_y_continuous(labels = function(x) paste0(x*100, "%")) +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position="none", 
        legend.title = element_blank(),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 10, face="bold")) + 
    facet_wrap(~variable, scales="free_y")

pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/feature_commentB.pdf", width=11, height=4)
feature_commentB
dev.off()

```


```{r }
user_count_plot.v <- newcomers_week_data %>%
  group_by(user_week) %>%
  summarise(volunteers =  n_distinct(user_id))

#user_count_plot <- merge(user_count_plot,user_count_plot.v, by="user_week",all.x = TRUE)

user_count_plot.m <- melt(user_count_plot, id.vars="user_week")

user_count_plot.m$variable <-  recode(user_count_plot.m$variable, comment_no = "Comments", questions = "Questions",links = "URLs", words = "Tokens",tags = "Tags", user_references = "@s")

commentfeature_grow <- ggplot(subset(user_count_plot.m, variable %in% c("Comments","Questions","URLs","Tokens","Tags","@s")), aes(as.factor(user_week), value)) + 
  geom_point(linewidth=.1) + 
  geom_smooth(size=.7, color="grey") +
  labs(x="Week",y="Mean use") + 
  theme_classic() + scale_color_nejm() +
  #scale_y_continuous(labels = function(x) paste0(x*100, "%")) +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position="none", 
        legend.title = element_blank(),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 10, face="bold")) + 
    facet_wrap(~variable, scales="free_y")


pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/feature_comment.pdf", width=11, height=4)
commentfeature_grow
dev.off()


### BAR 
commentfeature_growB <- user_count_plot.summary %>% 
 ggplot(subset(user_count_plot.summary, variable %in% c("Comments","Questions","URLs","Tokens","Tags","@s")), aes(x=user_week, y=value)) + 
  geom_bar(stat="identity", fill="grey", 
           position=position_dodge()) +
  #geom_errorbar(aes(ymin=value, ymax=value+sd), width=.2,
                 #position=position_dodge(.9)) + 
  labs(x="Week",y="Average") + 
  theme_linedraw() + 
  #scale_y_continuous(labels = function(x) paste0(x*100, "%")) +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position="none", 
        legend.title = element_blank(),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 10, face="bold")) + 
    facet_wrap(~variable, scales="free_y")



pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/commentfeature_growB.pdf", width=11, height=4)
commentfeature_growB
dev.off()

```






```{r }
# Visualization for number of newcomers vs. new commenters (bar chart)
if(any(grepl("package:plyr", search()))) detach("package:plyr") else message("plyr not loaded")
library(dplyr)

####### USER GROWTH
join_summary_week <- newcomers_data_org %>% 
   dplyr::group_by(join_date) %>% 
   dplyr::summarize(newcomers = length(user_id),
             newcomer_commenters = length(user_id[which(newcomer_comment >=1)]),
             percent_commenters = newcomer_commenters/newcomers)

join_summary_week_d <- newcomers_data_org %>% 
   group_by(join_date) %>% 
   summarize(newcomers = length(user_id),
             newcomer_commenters = length(user_id[which(newcomer_comment >=1)]),
             percent_commenters = newcomer_commenters/newcomers)

week_pct_comment <- ggplot(join_summary_week, aes(x=join_date, y=percent_commenters)) + 
  #geom_point() + 
  geom_smooth(size=1,color="black") +
  labs(x="Month",y="Newcomers") + 
  scale_x_date(date_labels="%b %y",date_breaks  ="6 month") + 
  scale_y_continuous(labels = function(x) paste0(round(x,digits=2), "%")) +
  theme_linedraw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position="none", 
        legend.title = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 18, face="bold")
        ) + 
    geom_vline(aes(xintercept=as.Date(join_summary_week[['join_date']][pettitt.test(join_summary_week$percent_commenters)$estimate]
)),size=1, linetype="dotted")  

newcomer_change_pt <- pettitt.test(join_summary_week$percent_commenters)


#pdf("/Users/jackson/Library/CloudStorage/Box-Box/_research/language[collab]/feature_count.pdf", width=11, height=4)
pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/pct_comment.pdf", width=11, height=6)
week_pct_comment
dev.off()
  
#Summarize amount of activity 
#newcomer_comments_summary <- newcomer_comments %>% tbl_summary()
# Test comparisons trial2 %>% tbl_summary(by = trt) %>% add_p() 



```


```{r}
## Cosine similarity 
newcomers_week_data$comment_week.y <- NULL
names(newcomers_week_data)[19] <- "comment_week"

newcomers_week_data$retained <- ifelse(newcomers_week_data$user_id %in% newcomers_data_org$user_id[which(newcomers_data_org$retained==1)],"Retained","Dropout")


####### VIZ BY THE NEWCOMERS TENURE WEEK IN THE PROJECT (NOT WHEN THEY COMMENT)
domain_similarityUW.viz <- newcomers_week_data %>% 
group_by(comment_week) %>% 
summarise(domain_cosine = round(mean(domain_cosine, na.rm=TRUE),digits=2)) %>% 
  ggplot(aes(factor(comment_week), domain_cosine, label=domain_cosine)) +
  geom_col(fill="grey") + 
  labs(x="Commenting week", y = "Domain similarity")+
    theme_linedraw() + 
    theme(
        axis.text = element_text(size = 14, face="bold"),
        axis.title = element_text(size = 14, face="bold"))  

field_similarityUW.viz <-  newcomers_week_data %>% 
group_by(comment_week) %>% 
summarise(science_cosine = round(mean(science_cosine, na.rm=TRUE),digits=2)) %>% 
  ggplot(aes(factor(comment_week), science_cosine, label=science_cosine)) +
  geom_col(fill="grey") + 
  labs(x="Commenting week", y = "Science similarity")+
   scale_fill_manual(values=c('black','lightgray'))+
    theme_linedraw() + 
    theme(
         axis.text = element_text(size = 14, face="bold"),
        axis.title = element_text(size = 14, face="bold"))

domain_similarity_groupUW.viz <-  newcomers_week_data %>% 
group_by(comment_week, retained) %>% 
summarise(domain_cosine = round(mean(domain_cosine, na.rm=TRUE),digits=2)) %>% 
  ggplot(aes(factor(comment_week), domain_cosine, label=domain_cosine, fill=as.factor(retained))) +
   geom_bar(stat="identity", position="dodge",preserve = "single")  +  
   geom_col(position = "dodge") +
  labs(x="Commenting week", y = "Domain similarity", fill="Status")+
   scale_fill_manual(values=c('darkgrey','lightgray'))+
    theme_linedraw() + 
     theme(legend.position = c(0.2, 0.8),
         axis.text = element_text(size = 14, face="bold"),
        axis.title = element_text(size = 14, face="bold"))

field_similarity_groupUW.viz <-  newcomers_week_data %>% 
group_by(comment_week, retained) %>% 
summarise(science_cosine = round(mean(science_cosine, na.rm=TRUE),digits=2)) %>% 
  ggplot(aes(factor(comment_week), science_cosine, label=science_cosine, fill=as.factor(retained))) +
   geom_bar(stat="identity", position="dodge",preserve = "single")  +  
   geom_col(position = "dodge") +
  labs(x="Commenting week", y = "Science similarity", fill="Status")+
   scale_fill_manual(values=c('darkgrey','lightgray'))+
    theme_linedraw() + 
     theme(legend.position = c(0.2, 0.8),
         axis.text = element_text(size = 14, face="bold"),
        axis.title = element_text(size = 14, face="bold"))

pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/similarity_growthU.pdf", width=11, height=4)
grid.arrange(domain_similarityUW.viz,field_similarityUW.viz, ncol = 2)
dev.off()


pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/similarity_growthUgroup.pdf", width=11, height=4)
grid.arrange(domain_similarity_groupUW.viz,field_similarity_groupUW.viz, ncol = 2)
dev.off()

library(gtsummary)

group_summarized <- newcomers_week_data %>%
  select(week_class,comment_no,newcomer_week_sessions,questions,links,words,tags,user_references,domain_words,field_words,domain_cosine,science_cosine,last_session,retained,comment_week) %>%
  #filter(comment_week <= 5) %>%
  group_by(retained,comment_week) %>%
 summarise_all(mean,na.rm=TRUE)

group_count <-   newcomers_week_data %>%
  select(week_class,comment_no,newcomer_week_sessions,questions,links,words,tags,user_references,domain_words,field_words,domain_cosine,science_cosine,last_session,retained,comment_week) %>%
  #filter(comment_week <= 5) %>%
  group_by(retained,comment_week) %>%
    summarise(n=n())

group_summarized <- merge(group_count,group_summarized, by=c("retained","comment_week"))

### Visualization of first 5 weeks incl lang. similarity
group_summarized.sum <- reshape2::melt(group_summarized, id.vars=c("comment_week","retained"))

group_summarized.sum$variable <-  recode(group_summarized.sum$variable, comment_no = "Comments", questions = "Questions",links = "URLs", words = "Tokens",tags = "Tags", user_references = "@s",domain_words = "Words(Domain)",field_words = "Words(Field)",science_change ="Change(Field)",domain_change="Change(Domain)",domain_cosine="Cosine(Domain)",science_cosine="Cosine(Field)")

group.viz <-  group_summarized.sum %>% 
filter(variable %in% c("Comments","Questions","URLs","Tokens","Tags","@s","Cosine(Domain)","Cosine(Field)"),comment_week <= 8) %>% 
group_by(comment_week, retained) %>% 
ggplot(aes(x=as.factor(comment_week), y=value)) + 
  geom_bar(aes(fill=retained),stat="identity", 
           position=position_dodge()) +
  scale_fill_manual(values=c("grey","black")) +
  #geom_errorbar(aes(ymin=value, ymax=value+sd), width=.2,
                 #position=position_dodge(.9)) + 
  labs(x="Week",y="Average") + 
  theme_linedraw() + 
  #scale_y_continuous(labels = function(x) paste0(x*100, "%")) +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position=c(.75, .25), 
        legend.title = element_blank(),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 10, face="bold")) + 
    facet_wrap(~variable, scales="free_y")

pdf("/Users/coreyjackson/Library/CloudStorage/Box-Box/_research/language[collab]/feature_retained.pdf", width=11, height=4)
group.viz
dev.off()



features_sens <- group_summarized.sum %>% 
  filter(comment_week <= 8,  variable %in% c("Comments","Questions","URLs","Tokens","Tags","@s","Cosine(Domain)","Cosine(Field)")) %>% 
  group_by(retained,variable) %>% 
  mutate(statistics = mk.test(value)$statistic,
         p_value = mk.test(value)$p.value,
         ) %>% 
  distinct(retained,variable,statistics,p_value)
```


```{r }
# ####### VIZ BY THE WEEK THAT A NEWCOMER COMMENTED
# domain_similarity.viz <- newcomers_week_data %>% 
# group_by(comment_week) %>% 
# summarise(domain_cosine = round(mean(domain_cosine, na.rm=TRUE),digits=2)) %>% 
#   
#   ggplot(aes(factor(comment_week), domain_cosine, label=domain_cosine)) +
#   geom_col() + 
#   labs(title="Domain similarity", 
#          x="Newcomer week", y = "Domain similarity")+
#    scale_fill_manual(values=c('black','lightgray'))+
#    theme_linedraw() + 
#     theme(
#         axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))  
# 
# field_similarity.viz <-  newcomers_week_data %>% 
# group_by(comment_week) %>% 
# summarise(science_cosine = round(mean(science_cosine, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(comment_week), science_cosine, label=science_cosine)) +
#   geom_col() + 
#   labs("Science similarity",x="Newcomer week", y = "Science similarity")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#   theme(
#         axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))  
# 
# domain_similarity_group.viz <-  newcomers_week_data %>% 
# group_by(comment_week, retained) %>% 
# summarise(domain_cosine = round(mean(domain_cosine, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(comment_week), domain_cosine, label=domain_cosine, fill=as.factor(retained))) +
#    geom_bar(stat="identity", position="dodge",preserve = "single")  +  
#    geom_col(position = "dodge") +
#   labs(title="Domain similarity", 
#          x="Newcomer week", y = "Domain similarity", fill="Status")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#    theme(legend.position = c(0.2, 0.8),
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
# 
# 
# field_similarity_group.viz <-  newcomers_week_data %>% 
# group_by(comment_week, retained) %>% 
# summarise(science_cosine = round(mean(science_cosine, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(comment_week), science_cosine, label=science_cosine, fill=as.factor(retained))) +
#    geom_bar(stat="identity", position="dodge",preserve = "single")  +  
#    geom_col(position = "dodge") +
#   labs(title="Science similarity", 
#          x="Newcomer week", y = "Science similarity", fill="Status")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#      theme(legend.position = c(0.2, 0.8),
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
# 
# ####### VIZ BY GAINS NEWCOMERS TENURE (comment_week) WEEK (domain_change, science_change)
# domain_change.viz <- newcomers_week_data %>% 
# group_by(comment_week) %>% 
# summarise(domain_change = round(mean(domain_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(comment_week), domain_change, label=domain_change)) +
#   geom_col() + 
#   labs(title="Domain similarity change", 
#          x="User week", y = "Domain similarity change")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#     theme(
#         axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))  
# 
# field_change.viz <-  newcomers_week_data %>% 
# group_by(comment_week) %>% 
# summarise(science_change = round(mean(science_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(comment_week), science_change, label=science_change)) +
#   geom_col() + 
#   labs("Science similarity change",x="User week", y = "Science similarity change")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#     theme(
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
# 
# domain_change_group.viz <-  newcomers_week_data %>% 
# group_by(comment_week, retained) %>% 
# summarise(domain_change = round(mean(domain_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(comment_week), domain_change, label=domain_change, fill=as.factor(retained))) +
#    geom_bar(stat="identity", position="dodge",preserve = "single")  +  
#    geom_col(position = "dodge") +
#    ylim(0,0.05) +
#   labs(title="Domain similarity change", 
#          x="User week", y = "Domain similarity change", fill="Status")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#      theme(legend.position = c(0.2, 0.8),
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
# 
# 
# field_change_group.viz <-  newcomers_week_data %>% 
# group_by(comment_week, retained) %>% 
# summarise(science_change = round(mean(science_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(comment_week), science_change, label=science_change, fill=as.factor(retained))) +
#    geom_bar(stat="identity", position="dodge",preserve = "single")  +  
#   ylim(0,0.05) +
#   geom_col(position = "dodge") +
#   labs(title="Science similarity change", 
#          x="User week", y = "Science similarity change", fill="Status")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#      theme(legend.position = c(0.5, 0.8),
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
# 
# ####### VIZ BY GAINS NEWCOMERS TENURE (by comment week order) WEEK (domain_change, science_change)
# 
# domain_changeUW.viz <- newcomers_week_data %>% 
# group_by(user_week) %>% 
# summarise(domain_change = round(mean(domain_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(user_week), domain_change, label=domain_change)) +
#   geom_col() + 
#   labs(title="Domain similarity change", 
#          x="Commenting week", y = "Domain similarity change")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#     theme(
#         axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))  
# 
# field_changeUW.viz <-  newcomers_week_data %>% 
# group_by(user_week) %>% 
# summarise(science_change = round(mean(science_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(user_week), science_change, label=science_change)) +
#   geom_col() + 
#   labs("Science similarity change",x="Commenting week", y = "Science similarity change")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#     theme(
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
# 
# domain_change_groupUW.viz <-  newcomers_week_data %>% 
# group_by(user_week, retained) %>% 
# summarise(domain_change = round(mean(domain_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(user_week), domain_change, label=domain_change, fill=as.factor(retained))) +
#    geom_bar(stat="identity", position="dodge",preserve = "single")  +  
#    geom_col(position = "dodge") +
#   labs(title="Domain similarity change", 
#          x="Commenting week", y = "Domain similarity change", fill="Status")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#      theme(legend.position = c(0.2, 0.8),
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
# 
# 
# field_change_groupUW.viz <-  newcomers_week_data %>% 
# group_by(user_week, retained) %>% 
# summarise(science_change = round(mean(science_change, na.rm=TRUE),digits=2)) %>% 
#   ggplot(aes(factor(user_week), science_change, label=science_change, fill=as.factor(retained))) +
#    geom_bar(stat="identity", position="dodge",preserve = "single")  +  
#    geom_col(position = "dodge") +
#   labs(title="Science similarity change", 
#          x="Commenting week", y = "Science similarity change", fill="Status")+
#    scale_fill_manual(values=c('black','lightgray'))+
#     theme_linedraw() + 
#      theme(legend.position = c(0.2, 0.8),
#          axis.text = element_text(size = 14, face="bold"),
#         axis.title = element_text(size = 14, face="bold"))
```


```{r, commentersmodels, echo=FALSE, include=FALSE, warning=FALSE}
################################
#   COMMENTERS MODELS          #
################################


##### Retained 
newcomer_info_commenters <- newcomers_data[which(newcomers_data$newcomer_comment>=1),]
newcomer_info_commenters <- newcomer_info_commenters[which(newcomer_info_commenters$newcomer_weeks >= 2 & newcomer_info_commenters$newcomer_comment>=1),] #1407

newcomer_info_commenters <- newcomer_info_commenters[,c(1:43,45,46,44)]

newcomer_info_commenters.show <- newcomer_info_commenters[,c(1,3,4,7,11,12,21,27,33:38,41,42,43,45,46)]
names(newcomer_info_commenters.show)[1:19] <- c("User","Classifications","Comments","Sessions","First_Comment_Sequence",
                                                "First_Comment_Session","Domain_Slope","Field_Slope","Questions","Replies", 
                                                "URLs","Tokens","Tags", "User_references","Days_Since_Launch","Domain_Cosine",
                                                "Field_Cosine","Threads_created","Class")

trainIndex_commenter <- createDataPartition(newcomer_info_commenters.show$Class, p = .7,
                                  list = FALSE,
                                  times = 1)
train_commenter <- newcomer_info_commenters.show[ trainIndex_commenter,]
valid_commenter <- newcomer_info_commenters.show[-trainIndex_commenter,]


retention_commenters.glm <- glm(Class ~ Classifications+Comments+Sessions+Questions+URLs+Tokens+Tags+User_references+Threads_created+Days_Since_Launch+First_Comment_Sequence+First_Comment_Session+Domain_Slope+Domain_Cosine+Field_Slope+Field_Cosine,data = train_commenter,family="binomial")

 logit2prob(coef(retention_commenters.glm)) #coefficients
 nagelkerke(retention_commenters.glm) # performance measures
 
 predictcommenter <- predict(retention_commenters.glm , newdata = valid_commenter, type = 'response')
 predictcommenter <- as.integer(predictcommenter>0.5)
 confusionMatrix(as.factor(predictcommenter),valid_commenter$Class)


########## PREPARING WEEKLY MODEL DATA 
week_model <- newcomers_week_data[which(!is.na(newcomers_week_data$variable)),]
week_model$week_class <- log(week_model$week_class+1)
week_model$comment_week <- as.factor(week_model$comment_week)

week_model.show <- week_model[,c(1,5:7,11:16,21,23,24,27)]
names(week_model.show)[1:14] <- c("User","Classifications","Comments","Sessions","Questions","Replies","URLs","Tokens","Tags",
                                  "User_references","Domain_Cosine","Last_session","Field_Cosine","Threads_created")
# Science cosine and change https://crumplab.com/psyc7709_2019/book/docs/a-tutorial-for-using-the-lme-function-from-the-nlme-package-.html 
science.lme <- lme(Field_Cosine ~ Classifications + Comments + Sessions + Questions + URLs + Tokens + Tags + User_references + Threads_created + Last_session, ~ 1 | User , data = week_model.show)
 nagelkerke(science.lme) # performance measures

##### Domain similarity score
domain.lme <- lme(Domain_Cosine ~ Classifications + Comments + Sessions + Questions + URLs + Tokens + Tags + User_references + Threads_created + Last_session, ~ 1 | User , data = week_model.show)
 nagelkerke(domain.lme) # performance measures
 

# https://easystats.github.io/performance/ 


```

## Retention models
```{r mixedmodel2, results = "asis", echo=TRUE, include=TRUE}
stargazer(retention_commenters.glm, science.lme,domain.lme, title="Retention Models",star.cutoffs = c(0.05, 0.01, 0.001), dep.var.labels=c("Retained (=1)"),
          object.names = TRUE,
          font.size = "small",
          align = TRUE,
          #omit.stat=c("f", "ser"),
          column.sep.width = "-10pt",
          no.space = TRUE, # to remove the spaces after each line of coefficients
          type = "latex",
          t.auto=F, p.auto=F, 
          #ci = TRUE, 
          report = ('vcs*'), 
          single.row = TRUE,
          digits=2
          
) #covariate.labels=c("Agent Centered","Authority Subject","Communal")
```


```{r, eval=FALSE, include=FALSE}

examples <- c("513912","1412875","315840","2538","1692922","2066383")

newcomers_data$domain_words <- stringr::str_count(newcomers_data$comment_body, paste(domain, collapse='|'))
newcomers_data$field_words <- stringr::str_count(newcomers_data$comment_body, paste(field, collapse='|'))


newcomers_case <- newcomers_data[which(newcomers_data$user_id %in% examples),]
comments_case <- comments[which(comments$comment_user_id %in% examples),]

## Count science/domain words in comments 

write.csv(newcomers_case,"/Volumes/cbjackson2/language models/narrativecase/newcomers_case.csv")
write.csv(comments_case,"/Volumes/cbjackson2/language models/narrativecase/comments_case.csv")

```

```{r }

#Compare over the weeks, the differences in sustained/dropout interactions
newcomer_com_week_summary <-  newcomer_comments 

# Report table


```

